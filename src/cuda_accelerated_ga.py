"""
CUDAç‰ˆGPUåŠ é€Ÿé—ä¼ ç®—æ³•å®ç°
æ”¯æŒNVIDIA GPU CUDAåŠ é€Ÿ
"""

import torch
import numpy as np
from dataclasses import dataclass
from typing import Tuple, Optional, Dict, Any
import time
import json
from pathlib import Path
import gc
import torch.jit

from cuda_gpu_utils import CudaGPUManager

try:
    from cuda_backtest_optimizer import CudaBacktestOptimizer
    BACKTEST_OPTIMIZER_AVAILABLE = True
except ImportError:
    BACKTEST_OPTIMIZER_AVAILABLE = False

try:
    from training_progress_monitor import TrainingProgressMonitor, SimpleProgressDisplay
    PROGRESS_MONITOR_AVAILABLE = True
except ImportError:
    PROGRESS_MONITOR_AVAILABLE = False

try:
    from performance_profiler import get_profiler, timer
    PERFORMANCE_PROFILER_AVAILABLE = True
except ImportError:
    PERFORMANCE_PROFILER_AVAILABLE = False
    # åˆ›å»ºç©ºçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    class timer:
        def __init__(self, *args, **kwargs):
            pass
        def __enter__(self):
            return self
        def __exit__(self, *args):
            pass


@dataclass
class CudaGAConfig:
    """CUDAé—ä¼ ç®—æ³•é…ç½®"""
    # åŸºæœ¬å‚æ•°
    population_size: int = 1000
    max_generations: int = 100
    mutation_rate: float = 0.01
    crossover_rate: float = 0.8
    elite_ratio: float = 0.1
    feature_dim: int = 1400
    
    # æ³¨æ„ï¼šäº¤æ˜“ç­–ç•¥å’Œé£é™©ç®¡ç†å‚æ•°ç°åœ¨ä½œä¸ºåŸºå› è‡ªåŠ¨è¿›åŒ–
    # - ä¹°å…¥é˜ˆå€¼: è‡ªåŠ¨åœ¨ [0.55, 0.8] èŒƒå›´å†…è¿›åŒ–
    # - å–å‡ºé˜ˆå€¼: è‡ªåŠ¨åœ¨ [0.2, 0.45] èŒƒå›´å†…è¿›åŒ–  
    # - æ­¢æŸæ¯”ä¾‹: è‡ªåŠ¨åœ¨ [0.02, 0.08] èŒƒå›´å†…è¿›åŒ–
    # - æœ€å¤§ä»“ä½: è‡ªåŠ¨åœ¨ [0.5, 1.0] èŒƒå›´å†…è¿›åŒ–
    # - æœ€å¤§å›æ’¤: è‡ªåŠ¨åœ¨ [0.1, 0.25] èŒƒå›´å†…è¿›åŒ–
    
    # é€‚åº”åº¦å‡½æ•°æƒé‡
    sharpe_weight: float = 0.5
    drawdown_weight: float = 0.3
    stability_weight: float = 0.2
    
    # GPUä¼˜åŒ–å‚æ•°
    batch_size: int = 1000
    early_stop_patience: int = 50
    use_torch_scan: bool = True
    
    def __post_init__(self):
        """éªŒè¯é…ç½®å‚æ•°"""
        assert self.population_size > 0, "ç§ç¾¤å¤§å°å¿…é¡»å¤§äº0"
        assert 0 < self.mutation_rate < 1, "å˜å¼‚ç‡å¿…é¡»åœ¨(0,1)ä¹‹é—´"
        assert 0 < self.crossover_rate < 1, "äº¤å‰ç‡å¿…é¡»åœ¨(0,1)ä¹‹é—´"
        assert 0 < self.elite_ratio < 1, "ç²¾è‹±æ¯”ä¾‹å¿…é¡»åœ¨(0,1)ä¹‹é—´"
        assert abs(self.sharpe_weight + self.drawdown_weight + self.stability_weight - 1.0) < 1e-6, \
            "é€‚åº”åº¦æƒé‡ä¹‹å’Œå¿…é¡»ç­‰äº1.0"

@torch.jit.script
def _jit_selection(population: torch.Tensor, fitness_scores: torch.Tensor, tournament_size: int) -> torch.Tensor:
    """JITç¼–è¯‘çš„é€‰æ‹©æ“ä½œ"""
    population_size = population.shape[0]
    selected_indices = torch.zeros(population_size, dtype=torch.long, device=population.device)
    
    for i in range(population_size):
        tournament_indices = torch.randint(0, population_size, (tournament_size,), device=population.device)
        tournament_fitness = fitness_scores[tournament_indices]
        winner_idx = tournament_indices[torch.argmax(tournament_fitness)]
        selected_indices[i] = winner_idx
        
    return population[selected_indices]

@torch.jit.script
def _jit_crossover(parents: torch.Tensor, crossover_rate: float) -> torch.Tensor:
    """JITç¼–è¯‘çš„äº¤å‰æ“ä½œ"""
    population_size, individual_size = parents.shape
    offspring = parents.clone()
    
    # JIT-friendly loop
    pairs = torch.randperm(population_size, device=parents.device).view(-1, 2)
    
    for i in range(pairs.shape[0]):
        parent1_idx = pairs[i, 0]
        parent2_idx = pairs[i, 1]
        
        if torch.rand(1, device=parents.device) < crossover_rate:
            mask = torch.rand(individual_size, device=parents.device) < 0.5
            
            # Safe swap for JIT
            temp = offspring[parent1_idx].clone()
            offspring[parent1_idx][mask] = offspring[parent2_idx][mask]
            offspring[parent2_idx][mask] = temp[mask]
            
    return offspring

class CudaGPUAcceleratedGA:
    """CUDA GPUåŠ é€Ÿé—ä¼ ç®—æ³•"""
    
    def __init__(self, config: CudaGAConfig, gpu_manager: CudaGPUManager):
        """
        åˆå§‹åŒ–é—ä¼ ç®—æ³•
        
        Args:
            config: ç®—æ³•é…ç½®
            gpu_manager: GPUç®¡ç†å™¨
        """
        self.config = config
        self.gpu_manager = gpu_manager
        self.device = gpu_manager.device
        
        # ç®—æ³•çŠ¶æ€
        self.generation = 0
        self.best_fitness = -float('inf')
        self.best_avg_fitness = -float('inf') # æ–°å¢ï¼šç”¨äºè·Ÿè¸ªå¹³å‡é€‚åº”åº¦
        self.best_individual = None
        self.fitness_history = []
        self.no_improvement_count = 0
        
        # GPUå¼ é‡
        self.population = None
        self.fitness_scores = None
        
        # åˆå§‹åŒ–å›æµ‹ä¼˜åŒ–å™¨
        if BACKTEST_OPTIMIZER_AVAILABLE:
            self.backtest_optimizer = CudaBacktestOptimizer(self.device)
            print("CUDAå›æµ‹ä¼˜åŒ–å™¨å·²å¯ç”¨")
        else:
            self.backtest_optimizer = None
            print("ä½¿ç”¨å†…ç½®å›æµ‹æ–¹æ³•")
        
        # åˆå§‹åŒ–è¿›åº¦ç›‘æ§å™¨
        self.progress_monitor = None
        self.use_detailed_progress = True
        
        print(f"CudaGPUAcceleratedGAåˆå§‹åŒ–å®Œæˆ")
        print(f"è®¾å¤‡: {self.device}")
        print(f"ç§ç¾¤å¤§å°: {config.population_size}")
        print(f"ç‰¹å¾ç»´åº¦: {config.feature_dim}")
    
    def initialize_population(self, seed: Optional[int] = None) -> None:
        """
        åˆå§‹åŒ–ç§ç¾¤
        
        Args:
            seed: éšæœºç§å­
        """
        with timer("initialize_population", "ga"):
            if seed is not None:
                torch.manual_seed(seed)
                np.random.seed(seed)
            
            print("åˆå§‹åŒ–ç§ç¾¤...")
            
            # åœ¨GPUä¸Šåˆ›å»ºç§ç¾¤
            # æ¯ä¸ªä¸ªä½“åŒ…å«: [æƒé‡(feature_dim), åç½®, ä¹°å…¥é˜ˆå€¼, å–å‡ºé˜ˆå€¼, æ­¢æŸ, æœ€å¤§ä»“ä½, æœ€å¤§å›æ’¤, äº¤æ˜“ä»“ä½]
            individual_size = self.config.feature_dim + 7
            
            with timer("create_population_tensor", "ga"):
                self.population = torch.randn(
                    self.config.population_size, 
                    individual_size,
                    device=self.device,
                    dtype=torch.float32
                )
            
            with timer("initialize_weights", "ga"):
                # åˆå§‹åŒ–æƒé‡éƒ¨åˆ† (å‰feature_dimä¸ªå‚æ•°)
                self.population[:, :self.config.feature_dim] *= 0.1
            
            with timer("initialize_trading_params", "ga"):
                # åˆå§‹åŒ–å…¶ä»–å‚æ•°
                self.population[:, self.config.feature_dim] = torch.randn(self.config.population_size, device=self.device) * 0.1  # åç½®
                self.population[:, self.config.feature_dim + 1] = torch.sigmoid(torch.randn(self.config.population_size, device=self.device)) * 0.25 + 0.55  # ä¹°å…¥é˜ˆå€¼ [0.55, 0.8]
                self.population[:, self.config.feature_dim + 2] = torch.sigmoid(torch.randn(self.config.population_size, device=self.device)) * 0.25 + 0.2   # å–å‡ºé˜ˆå€¼ [0.2, 0.45]
                self.population[:, self.config.feature_dim + 3] = torch.sigmoid(torch.randn(self.config.population_size, device=self.device)) * 0.06 + 0.02  # æ­¢æŸ [0.02, 0.08]
                self.population[:, self.config.feature_dim + 4] = torch.sigmoid(torch.randn(self.config.population_size, device=self.device)) * 0.5 + 0.5   # æœ€å¤§ä»“ä½ [0.5, 1.0]
                self.population[:, self.config.feature_dim + 5] = torch.sigmoid(torch.randn(self.config.population_size, device=self.device)) * 0.15 + 0.1  # æœ€å¤§å›æ’¤ [0.1, 0.25]
                self.population[:, self.config.feature_dim + 6] = torch.sigmoid(torch.randn(self.config.population_size, device=self.device)) * 0.8 + 0.01   # äº¤æ˜“ä»“ä½ [0.2, 1.0]
            
            # åˆå§‹åŒ–é€‚åº”åº¦åˆ†æ•°
            self.fitness_scores = torch.zeros(self.config.population_size, device=self.device)
            
            print(f"ç§ç¾¤åˆå§‹åŒ–å®Œæˆ: {self.population.shape}")
    
    def evaluate_fitness_batch(self, features: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:
        """
        æ‰¹é‡è¯„ä¼°ç§ç¾¤é€‚åº”åº¦
        
        Args:
            features: ç‰¹å¾æ•°æ® [n_samples, feature_dim]
            labels: æ ‡ç­¾æ•°æ® [n_samples]
            
        Returns:
            é€‚åº”åº¦åˆ†æ•° [population_size]
        """
        with timer("evaluate_fitness_batch", "ga"):
            n_samples = features.shape[0]
            population_size = self.population.shape[0]
            
            with timer("extract_parameters", "ga"):
                # æå–ä¸ªä½“å‚æ•°
                weights = self.population[:, :self.config.feature_dim]  # [pop_size, feature_dim]
                biases = self.population[:, self.config.feature_dim]    # [pop_size]
                buy_thresholds = self.population[:, self.config.feature_dim + 1]   # [pop_size]
                sell_thresholds = self.population[:, self.config.feature_dim + 2]  # [pop_size]
                stop_losses = self.population[:, self.config.feature_dim + 3]      # [pop_size]
                max_positions = self.population[:, self.config.feature_dim + 4]    # [pop_size]
                max_drawdowns = self.population[:, self.config.feature_dim + 5]    # [pop_size]
                trade_positions = self.population[:, self.config.feature_dim + 6]  # [pop_size]
            
            with timer("compute_signals", "ga"):
                # è®¡ç®—é¢„æµ‹ä¿¡å· [pop_size, n_samples]
                signals = torch.sigmoid(torch.matmul(weights, features.T) + biases.unsqueeze(1))
            
            with timer("backtest", "ga"):
                # ä½¿ç”¨CUDAä¼˜åŒ–çš„å‘é‡åŒ–å›æµ‹
                if self.backtest_optimizer is not None:
                    # ä½¿ç”¨ä¸“é—¨çš„CUDAå›æµ‹ä¼˜åŒ–å™¨
                    if self.config.use_torch_scan:
                        with timer("backtest_v3", "backtest"):
                            # é«˜ç²¾åº¦æ¨¡å¼ (ä½¿ç”¨v4 scan-style JITå®ç°)
                            fitness_scores = self.backtest_optimizer.vectorized_backtest_v4_scan_style(
                                signals, labels, buy_thresholds, sell_thresholds, 
                                max_positions, stop_losses, max_drawdowns
                            )
                    else:
                        with timer("backtest_v2", "backtest"):
                            # é«˜é€Ÿæ¨¡å¼
                            fitness_scores = self.backtest_optimizer.vectorized_backtest_v2(
                                signals, labels, buy_thresholds, sell_thresholds, max_positions, trade_positions
                            )
                else:
                    # ä½¿ç”¨å†…ç½®å›æµ‹æ–¹æ³•
                    if self.config.use_torch_scan:
                        with timer("advanced_vectorized_backtest", "backtest"):
                            fitness_scores = self._advanced_vectorized_backtest(
                                signals, labels, buy_thresholds, sell_thresholds, 
                                stop_losses, max_positions, max_drawdowns
                            )
                    else:
                        with timer("vectorized_backtest", "backtest"):
                            fitness_scores = self._vectorized_backtest(
                                signals, labels, buy_thresholds, sell_thresholds,
                                stop_losses, max_positions, max_drawdowns
                            )
            
            return fitness_scores, sharpe_ratios, max_drawdowns_calc, normalized_trades
    
    def _backtest_with_scan(self, signals: torch.Tensor, labels: torch.Tensor,
                           buy_thresholds: torch.Tensor, sell_thresholds: torch.Tensor,
                           stop_losses: torch.Tensor, max_positions: torch.Tensor, max_drawdowns: torch.Tensor) -> torch.Tensor:
        """ä½¿ç”¨torch.scançš„ä¼˜åŒ–å›æµ‹"""
        population_size, n_samples = signals.shape
        
        # åˆå§‹çŠ¶æ€
        initial_state = {
            'position': torch.zeros(population_size, device=self.device),
            'cash': torch.ones(population_size, device=self.device),
            'portfolio_value': torch.ones(population_size, device=self.device),
            'entry_price': torch.zeros(population_size, device=self.device),
            'returns': torch.zeros(population_size, device=self.device),
            'trade_count': torch.zeros(population_size, device=self.device),
            'max_portfolio': torch.ones(population_size, device=self.device),
        }
        
        def scan_fn(state, inputs):
            signal, price_return = inputs
            
            # å½“å‰ä»·æ ¼å˜åŒ–
            current_return = price_return
            
            # æ›´æ–°æŒä»“ä»·å€¼
            new_portfolio_value = state['cash'] + state['position'] * (1 + current_return)
            
            # äº¤æ˜“å†³ç­–
            buy_signal = (signal > buy_thresholds.unsqueeze(1)) & (state['position'] == 0)
            sell_signal = (signal < sell_thresholds.unsqueeze(1)) & (state['position'] > 0)
            
            # æ­¢æŸæ£€æŸ¥
            if torch.any(state['position'] > 0):
                current_loss = (current_return - state['entry_price']) / state['entry_price']
                stop_loss_signal = (current_loss < -stop_losses.unsqueeze(1)) & (state['position'] > 0)
                sell_signal = sell_signal | stop_loss_signal
            
            # æ‰§è¡Œä¹°å…¥
            new_position = torch.where(
                buy_signal.squeeze(),
                torch.clamp(max_positions * new_portfolio_value, 0, new_portfolio_value),
                state['position']
            )
            new_cash = torch.where(
                buy_signal.squeeze(),
                new_portfolio_value - new_position,
                state['cash']
            )
            new_entry_price = torch.where(
                buy_signal.squeeze(),
                torch.zeros_like(state['entry_price']),  # ä»¥å½“å‰ä»·æ ¼ä¹°å…¥
                state['entry_price']
            )
            
            # æ‰§è¡Œå–å‡º
            new_cash = torch.where(
                sell_signal.squeeze(),
                new_cash + new_position * (1 + current_return),
                new_cash
            )
            new_position = torch.where(
                sell_signal.squeeze(),
                torch.zeros_like(new_position),
                new_position
            )
            
            # æ›´æ–°ç»Ÿè®¡
            new_trade_count = state['trade_count'] + buy_signal.squeeze().float() + sell_signal.squeeze().float()
            new_max_portfolio = torch.maximum(state['max_portfolio'], new_portfolio_value)
            
            # è®¡ç®—æ”¶ç›Š
            new_returns = (new_portfolio_value - 1.0)
            
            new_state = {
                'position': new_position,
                'cash': new_cash,
                'portfolio_value': new_portfolio_value,
                'entry_price': new_entry_price,
                'returns': new_returns,
                'trade_count': new_trade_count,
                'max_portfolio': new_max_portfolio,
            }
            
            return new_state, new_returns
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        inputs = (signals.T.unsqueeze(-1), labels.unsqueeze(0).unsqueeze(-1))  # [n_samples, pop_size, 1]
        
        # torch.func.scanåœ¨æŸäº›PyTorchç‰ˆæœ¬ä¸­ä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨ä¼˜åŒ–çš„ä¼ ç»Ÿæ–¹æ³•
        return self._backtest_traditional(signals, labels, buy_thresholds, sell_thresholds, stop_losses, max_positions, max_drawdowns)
        
        # ç»¼åˆé€‚åº”åº¦
        fitness = (self.config.sharpe_weight * sharpe_ratios - 
                  self.config.drawdown_weight * drawdowns +
                  self.config.stability_weight * normalized_trade_counts)
        
        return fitness
    
    def _backtest_traditional(self, signals: torch.Tensor, labels: torch.Tensor,
                             buy_thresholds: torch.Tensor, sell_thresholds: torch.Tensor,
                             stop_losses: torch.Tensor, max_positions: torch.Tensor, max_drawdowns: torch.Tensor) -> torch.Tensor:
        """CUDAä¼˜åŒ–çš„å‘é‡åŒ–å›æµ‹æ–¹æ³•"""
        population_size, n_samples = signals.shape
        
        # ä½¿ç”¨å‘é‡åŒ–æ“ä½œè¿›è¡Œæ‰¹é‡å›æµ‹ï¼Œé¿å…å¾ªç¯
        return self._vectorized_backtest(signals, labels, buy_thresholds, sell_thresholds, stop_losses, max_positions, max_drawdowns)
    
    def _vectorized_backtest(self, signals: torch.Tensor, labels: torch.Tensor,
                           buy_thresholds: torch.Tensor, sell_thresholds: torch.Tensor,
                           stop_losses: torch.Tensor, max_positions: torch.Tensor, max_drawdowns: torch.Tensor) -> torch.Tensor:
        """å®Œå…¨å‘é‡åŒ–çš„CUDAå›æµ‹å®ç°"""
        population_size, n_samples = signals.shape
        
        # æ‰©å±•é˜ˆå€¼ç»´åº¦ä»¥åŒ¹é…ä¿¡å·
        buy_thresholds = buy_thresholds.unsqueeze(1)  # [pop_size, 1]
        sell_thresholds = sell_thresholds.unsqueeze(1)  # [pop_size, 1]
        stop_losses = stop_losses.unsqueeze(1)  # [pop_size, 1]
        max_positions = max_positions.unsqueeze(1)  # [pop_size, 1]
        max_drawdowns = max_drawdowns.unsqueeze(1)  # [pop_size, 1]
        
        # ç”Ÿæˆäº¤æ˜“ä¿¡å·çŸ©é˜µ
        buy_signals = (signals > buy_thresholds).float()  # [pop_size, n_samples]
        sell_signals = (signals < sell_thresholds).float()  # [pop_size, n_samples]
        
        # è®¡ç®—ç´¯ç§¯æ”¶ç›Š
        cumulative_returns = torch.cumprod(1 + labels.unsqueeze(0).expand(population_size, -1), dim=1)
        
        # ç®€åŒ–çš„äº¤æ˜“æ¨¡æ‹Ÿï¼šä½¿ç”¨ä¿¡å·å¼ºåº¦ä½œä¸ºæƒé‡
        signal_strength = torch.sigmoid((signals - 0.5) * 4)  # å°†ä¿¡å·æ˜ å°„åˆ°[0,1]
        
        # è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹çš„ä»“ä½ï¼ˆåŸºäºä¿¡å·å¼ºåº¦ï¼‰
        positions = signal_strength * max_positions.squeeze(1).unsqueeze(1)
        
        # è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹çš„æ”¶ç›Š
        period_returns = labels.unsqueeze(0).expand(population_size, -1)
        portfolio_returns = positions * period_returns
        
        # è®¡ç®—ç´¯ç§¯ç»„åˆä»·å€¼
        portfolio_values = torch.cumprod(1 + portfolio_returns, dim=1)
        final_values = portfolio_values[:, -1]
        
        # è®¡ç®—å¤æ™®æ¯”ç‡
        returns_std = torch.std(portfolio_returns, dim=1) + 1e-8
        mean_returns = torch.mean(portfolio_returns, dim=1)
        sharpe_ratios = mean_returns / returns_std
        
        # è®¡ç®—æœ€å¤§å›æ’¤
        running_max = torch.cummax(portfolio_values, dim=1)[0]
        drawdowns = (running_max - portfolio_values) / running_max
        max_drawdowns = torch.max(drawdowns, dim=1)[0]
        
        # è®¡ç®—äº¤æ˜“æ´»è·ƒåº¦
        position_changes = torch.abs(torch.diff(positions, dim=1))
        trade_activity = torch.mean(position_changes, dim=1)
        normalized_activity = torch.clamp(trade_activity, 0.0, 1.0)
        
        # ç»¼åˆé€‚åº”åº¦è¯„åˆ†
        fitness = (self.config.sharpe_weight * sharpe_ratios - 
                  self.config.drawdown_weight * max_drawdowns -
                  self.config.stability_weight * normalized_activity)
        
        return fitness
    
    def _advanced_vectorized_backtest(self, signals: torch.Tensor, labels: torch.Tensor,
                                     buy_thresholds: torch.Tensor, sell_thresholds: torch.Tensor,
                                     stop_losses: torch.Tensor, max_positions: torch.Tensor, max_drawdowns: torch.Tensor) -> torch.Tensor:
        """é«˜çº§CUDAå‘é‡åŒ–å›æµ‹ï¼Œæ›´ç²¾ç¡®çš„äº¤æ˜“æ¨¡æ‹Ÿï¼ˆå·²ä¿®å¤æ­¢æŸé€»è¾‘ï¼‰"""
        population_size, n_samples = signals.shape
        
        # æ‰©å±•ç»´åº¦
        buy_thresholds = buy_thresholds.unsqueeze(1)
        sell_thresholds = sell_thresholds.unsqueeze(1)
        stop_losses = stop_losses.unsqueeze(1)
        max_positions = max_positions.unsqueeze(1)
        max_drawdowns_param = max_drawdowns.unsqueeze(1) # é‡å‘½åä»¥é¿å…ä¸è®¡ç®—å‡ºçš„æœ€å¤§å›æ’¤å˜é‡å†²çª
        
        # ç”Ÿæˆäº¤æ˜“å†³ç­–çŸ©é˜µ
        buy_signals = (signals > buy_thresholds).float()
        sell_signals = (signals < sell_thresholds).float()
        
        # åˆå§‹åŒ–çŠ¶æ€çŸ©é˜µ
        positions = torch.zeros(population_size, n_samples + 1, device=self.device)
        portfolio_values = torch.ones(population_size, n_samples + 1, device=self.device)
        entry_prices = torch.zeros(population_size, device=self.device) # ç®€åŒ–ï¼šåªè·Ÿè¸ªå½“å‰æŒä»“çš„å…¥åœºä»·

        # æ¨¡æ‹Ÿä»·æ ¼åºåˆ—ï¼Œç”¨äºæ­¢æŸè®¡ç®—
        # ä»1å¼€å§‹ç´¯ç§¯ä¹˜ä»¥(1+return)
        prices = torch.cat([torch.ones(1, device=self.device), 1 + labels]).cumprod(0)

        # å‘é‡åŒ–äº¤æ˜“æ¨¡æ‹Ÿ
        for t in range(n_samples):
            current_return = labels[t]
            # tæ—¶åˆ»çš„ä»·æ ¼ä»£è¡¨t-1åˆ°tçš„å˜åŒ–åçš„ä»·æ ¼
            current_price = prices[t+1]

            # å½“å‰ä»“ä½çŠ¶æ€
            current_positions = positions[:, t]
            current_values = portfolio_values[:, t]
            
            # æ›´æ–°æŠ•èµ„ç»„åˆä»·å€¼ï¼ˆåŸºäºå‰ä¸€å¤©çš„ä»·å€¼å’Œä»Šå¤©çš„æŒä»“æ”¶ç›Šï¼‰
            updated_values = current_values * (1 + current_positions * current_return)
            
            # è®¡ç®—å½“å‰æœ€é«˜ç‚¹å’Œå›æ’¤
            # ä½¿ç”¨æ›´æ–°åçš„ä»·å€¼æ¥è®¡ç®—å½“æ—¥å›æ’¤
            running_max = torch.maximum(portfolio_values[:, :t+1].max(dim=1)[0], updated_values)
            current_drawdown = (running_max - updated_values) / (running_max + 1e-8)
            
            # æ­¢æŸå†³ç­– (æ ¸å¿ƒä¿®å¤)
            # å½“æŒæœ‰ä»“ä½æ—¶ï¼Œæ£€æŸ¥å½“å‰ä»·æ ¼æ˜¯å¦ä½äºå…¥åœºä»·æ ¼çš„ä¸€å®šæ¯”ä¾‹
            stop_loss_triggered = (current_positions > 0) & (entry_prices > 0) & (current_price < entry_prices * (1 - stop_losses.squeeze(1)))

            # äº¤æ˜“å†³ç­–ï¼ˆåŒ…å«æœ€å¤§å›æ’¤é™åˆ¶å’Œæ­¢æŸï¼‰
            can_buy = (current_positions == 0) & (buy_signals[:, t] == 1) & (current_drawdown < max_drawdowns_param.squeeze(1))
            can_sell = (current_positions > 0) & ((sell_signals[:, t] == 1) | stop_loss_triggered | (current_drawdown > max_drawdowns_param.squeeze(1)))
            
            # æ‰§è¡Œäº¤æ˜“
            new_positions = current_positions.clone()
            
            # ä¹°å…¥ï¼šè®¾ç½®ä»“ä½å¹¶è®°å½•å…¥åœºä»·æ ¼
            buy_position = max_positions.squeeze(1)
            new_positions = torch.where(can_buy, buy_position, new_positions)
            entry_prices = torch.where(can_buy, current_price, entry_prices)

            # å–å‡ºï¼šæ¸…ç©ºä»“ä½å’Œå…¥åœºä»·æ ¼
            new_positions = torch.where(can_sell, torch.zeros_like(new_positions), new_positions)
            entry_prices = torch.where(can_sell, torch.zeros_like(entry_prices), entry_prices)
            
            # æ›´æ–°çŠ¶æ€
            positions[:, t + 1] = new_positions
            portfolio_values[:, t + 1] = updated_values
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        final_values = portfolio_values[:, -1]
        
        # è®¡ç®—æ”¶ç›Šåºåˆ—
        returns = torch.diff(portfolio_values, dim=1) / (portfolio_values[:, :-1] + 1e-8)
        
        # å¤æ™®æ¯”ç‡
        mean_returns = torch.mean(returns, dim=1)
        std_returns = torch.std(returns, dim=1) + 1e-8
        sharpe_ratios = mean_returns / std_returns
        
        # æœ€å¤§å›æ’¤
        running_max_final = torch.cummax(portfolio_values, dim=1)[0]
        drawdowns_final = (running_max_final - portfolio_values) / (running_max_final + 1e-8)
        max_drawdowns_calc = torch.max(drawdowns_final, dim=1)[0]
        
        # äº¤æ˜“é¢‘ç‡
        position_changes = torch.abs(torch.diff(positions, dim=1))
        trade_frequency = torch.sum(position_changes > 0, dim=1).float() / n_samples
        normalized_frequency = torch.clamp(trade_frequency, 0.0, 1.0)
        
        # ç»¼åˆé€‚åº”åº¦
        fitness = (self.config.sharpe_weight * sharpe_ratios - 
                  self.config.drawdown_weight * max_drawdowns_calc -
                  self.config.stability_weight * normalized_frequency)
        
        # å¤„ç†NaNå’Œinfå€¼ï¼Œé¿å…å½±å“é—ä¼ ç®—æ³•è¿›ç¨‹
        fitness = torch.nan_to_num(fitness, nan=-10.0, posinf=0.0, neginf=-10.0)
        
        return fitness
    
    def selection(self) -> torch.Tensor:
        """é€‰æ‹©æ“ä½œ - é”¦æ ‡èµ›é€‰æ‹©"""
        with timer("selection", "ga"):
            tournament_size = max(2, self.config.population_size // 20)
            return _jit_selection(self.population, self.fitness_scores, tournament_size)
    
    def crossover(self, parents: torch.Tensor) -> torch.Tensor:
        """äº¤å‰æ“ä½œ - å‡åŒ€äº¤å‰"""
        with timer("crossover", "ga"):
            return _jit_crossover(parents, self.config.crossover_rate)
    
    def mutation(self, population: torch.Tensor) -> torch.Tensor:
        """å˜å¼‚æ“ä½œ"""
        with timer("mutation", "ga"):
            population_size, individual_size = population.shape
            mutated = population.clone()
            
            with timer("weight_mutation", "ga"):
                # æƒé‡å˜å¼‚
                weight_mask = torch.rand(population_size, self.config.feature_dim, device=self.device) < self.config.mutation_rate
                weight_noise = torch.randn(population_size, self.config.feature_dim, device=self.device) * 0.01
                mutated[:, :self.config.feature_dim] += weight_mask * weight_noise
            
            with timer("param_mutation", "ga"):
                # å…¶ä»–å‚æ•°å˜å¼‚ (å·²ä¿®å¤ç»´åº¦é—®é¢˜)
                param_count = 7  # æ€»å…±æœ‰7ä¸ªé¢å¤–å‚æ•°
                param_mask = torch.rand(population_size, param_count, device=self.device) < self.config.mutation_rate
                param_noise = torch.randn(population_size, param_count, device=self.device) * 0.01
                
                # åº”ç”¨å˜å¼‚åˆ°æ‰€æœ‰7ä¸ªå‚æ•°
                mutated[:, self.config.feature_dim:] += param_mask * param_noise
                
                # ç¡®ä¿å‚æ•°åœ¨åˆç†èŒƒå›´å†… (å·²æ·»åŠ äº¤æ˜“ä»“ä½é™åˆ¶)
                mutated[:, self.config.feature_dim + 1] = torch.clamp(mutated[:, self.config.feature_dim + 1], 0.55, 0.8)   # ä¹°å…¥é˜ˆå€¼
                mutated[:, self.config.feature_dim + 2] = torch.clamp(mutated[:, self.config.feature_dim + 2], 0.2, 0.45)   # å–å‡ºé˜ˆå€¼
                mutated[:, self.config.feature_dim + 3] = torch.clamp(mutated[:, self.config.feature_dim + 3], 0.02, 0.08)   # æ­¢æŸ
                mutated[:, self.config.feature_dim + 4] = torch.clamp(mutated[:, self.config.feature_dim + 4], 0.5, 1.0)    # æœ€å¤§ä»“ä½
                mutated[:, self.config.feature_dim + 5] = torch.clamp(mutated[:, self.config.feature_dim + 5], 0.1, 0.25)   # æœ€å¤§å›æ’¤
                mutated[:, self.config.feature_dim + 6] = torch.clamp(mutated[:, self.config.feature_dim + 6], 0.01, 0.81)  # äº¤æ˜“ä»“ä½
            
            return mutated
    
    def evolve_one_generation(self, features: torch.Tensor, labels: torch.Tensor, output_dir: Optional[Path] = None) -> Dict[str, float]:
        """è¿›åŒ–ä¸€ä»£"""
        with timer("evolve_one_generation", "ga"):
            start_time = time.time()
            
            # è¯„ä¼°é€‚åº”åº¦
            self.fitness_scores = self.evaluate_fitness_batch(features, labels)
            
            with timer("update_best_individual", "ga"):
                # è®°å½•æœ€ä½³ä¸ªä½“
                current_avg_fitness = torch.mean(self.fitness_scores).item()
                best_idx = torch.argmax(self.fitness_scores)
                current_best_fitness = self.fitness_scores[best_idx].item()

                if current_avg_fitness > self.best_avg_fitness:
                    self.best_avg_fitness = current_avg_fitness
                    self.no_improvement_count = 0
                    # ç«‹å³ä¿å­˜æœ€ä½³ä¸ªä½“ï¼Œè¦†ç›–æ—§æ–‡ä»¶
                    if output_dir and self.best_individual is not None:
                        best_path = output_dir / "best_individual.npy"
                        np.save(best_path, self.best_individual)
                        print(f"ğŸ’¾ æ–°çš„æœ€ä½³ä¸ªä½“å·²ä¿å­˜: {best_path.name} (å¹³å‡é€‚åº”åº¦: {self.best_avg_fitness:.4f})")
                else:
                    self.no_improvement_count += 1

                # å§‹ç»ˆæ›´æ–°æœ€ä½³ä¸ªä½“ï¼ˆåŸºäºæœ€é«˜é€‚åº”åº¦ï¼‰
                if current_best_fitness > self.best_fitness:
                    self.best_fitness = current_best_fitness
                    self.best_individual = self.gpu_manager.to_cpu(self.population[best_idx])
            
            with timer("elite_selection", "ga"):
                # ç²¾è‹±ä¿ç•™
                elite_size = int(self.config.population_size * self.config.elite_ratio)
                elite_indices = torch.topk(self.fitness_scores, elite_size).indices
                elite_population = self.population[elite_indices]
            
            # é€‰æ‹©ã€äº¤å‰ã€å˜å¼‚
            selected = self.selection()
            offspring = self.crossover(selected)
            mutated = self.mutation(offspring)
            
            with timer("population_replacement", "ga"):
                # æ–°ç§ç¾¤ = ç²¾è‹± + å˜å¼‚åä»£
                new_population = torch.cat([elite_population, mutated[elite_size:]], dim=0)
                self.population = new_population
            
            self.generation += 1
            generation_time = time.time() - start_time
            
            # è®°å½•å†å²
            stats = {
                'generation': self.generation,
                'best_fitness': current_best_fitness,
                'avg_fitness': torch.mean(self.fitness_scores).item(),
                'std_fitness': torch.std(self.fitness_scores).item(),
                'avg_sharpe_ratio': torch.mean(sharpe_ratios).item(),
                'avg_max_drawdown': torch.mean(max_drawdowns_calc).item(),
                'avg_trade_frequency': torch.mean(normalized_trades).item(),
                'generation_time': generation_time,
                'no_improvement_count': self.no_improvement_count
            }
            
            self.fitness_history.append(stats)
            
            return stats
    
    def evolve(self, features: torch.Tensor, labels: torch.Tensor,
               save_checkpoints: bool = True,
               checkpoint_dir: Optional[Path] = None,
               save_generation_results: bool = True,
               generation_log_file: Optional[Path] = None,
               generation_log_interval: int = 1,
               auto_save_best: bool = True,
               output_dir: Optional[Path] = None,
               show_detailed_progress: bool = True,
               progress_update_interval: float = 1.0) -> Dict[str, Any]:
        """
        ä¸»è¿›åŒ–å¾ªç¯
        
        Args:
            features: è®­ç»ƒç‰¹å¾
            labels: è®­ç»ƒæ ‡ç­¾
            save_checkpoints: æ˜¯å¦ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint_dir: æ£€æŸ¥ç‚¹ç›®å½•
            save_generation_results: æ˜¯å¦ä¿å­˜æ¯ä»£ç»“æœ
            generation_log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            generation_log_interval: æ—¥å¿—è®°å½•é—´éš”
            auto_save_best: æ˜¯å¦è‡ªåŠ¨ä¿å­˜æœ€ä½³ä¸ªä½“
            output_dir: è¾“å‡ºç›®å½•
            show_detailed_progress: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¿›åº¦
            progress_update_interval: è¿›åº¦æ›´æ–°é—´éš”
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        # åˆå§‹åŒ–è¿›åº¦ç›‘æ§å™¨
        if PROGRESS_MONITOR_AVAILABLE and show_detailed_progress:
            self.progress_monitor = TrainingProgressMonitor(
                log_file=generation_log_file,
                update_interval=progress_update_interval
            )
            self.progress_monitor.start_training(
                total_generations=self.config.max_generations,
                early_stop_patience=self.config.early_stop_patience
            )
        else:
            # ä½¿ç”¨ç®€åŒ–æ˜¾ç¤ºå™¨
            self.progress_monitor = SimpleProgressDisplay()
            self.progress_monitor.start_training(self.config.max_generations)
        
        start_time = time.time()
        
        # ç¡®ä¿æ•°æ®åœ¨GPUä¸Š
        features = self.gpu_manager.to_gpu(features)
        labels = self.gpu_manager.to_gpu(labels)
        
        try:
            while True:
                # æ£€æŸ¥åœæ­¢æ¡ä»¶
                if self.config.max_generations > 0 and self.generation >= self.config.max_generations:
                    print(f"è¾¾åˆ°æœ€å¤§ä»£æ•° {self.config.max_generations}ï¼Œåœæ­¢è®­ç»ƒ")
                    break
                
                if self.no_improvement_count >= self.config.early_stop_patience:
                    print(f"è¿ç»­ {self.config.early_stop_patience} ä»£æ— æ”¹è¿›ï¼Œæ—©åœ")
                    break
                
                # è¿›åŒ–ä¸€ä»£
                stats = self.evolve_one_generation(features, labels, output_dir)
                
                # æ·»åŠ GPUå†…å­˜ä¿¡æ¯åˆ°ç»Ÿè®¡æ•°æ®
                if torch.cuda.is_available():
                    stats['gpu_memory_allocated'] = torch.cuda.memory_allocated() / 1e9
                    stats['gpu_memory_reserved'] = torch.cuda.memory_reserved() / 1e9
                
                # æ·»åŠ ç³»ç»Ÿå†…å­˜ä¿¡æ¯
                import psutil
                stats['system_memory_gb'] = psutil.virtual_memory().used / 1e9
                
                # æ›´æ–°è¿›åº¦ç›‘æ§å™¨
                if hasattr(self, 'progress_monitor') and self.progress_monitor:
                    self.progress_monitor.update_generation(self.generation, stats)
                
                # ä¿å­˜æ—¥å¿— (æ ¹æ®ç”¨æˆ·è¦æ±‚å·²ç¦ç”¨)
                # if save_generation_results and generation_log_file and self.generation % generation_log_interval == 0:
                #     with open(generation_log_file, 'a', encoding='utf-8') as f:
                #         json.dump(stats, f, ensure_ascii=False)
                #         f.write('\n')
                
                
                
                
                
                # å®šæœŸæ¸…ç†GPUç¼“å­˜
                if self.generation % 10 == 0:
                    self.gpu_manager.clear_cache()
        
        except KeyboardInterrupt:
            print("\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise
        
        total_time = time.time() - start_time

        # åœ¨è®­ç»ƒç»“æŸæ—¶ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹
        if save_checkpoints and checkpoint_dir:
            final_checkpoint_path = checkpoint_dir / "final_checkpoint.pt"
            self.save_checkpoint(str(final_checkpoint_path))
            print(f"ğŸ’¾ æœ€ç»ˆæ£€æŸ¥ç‚¹å·²ä¿å­˜: {final_checkpoint_path.name}")

        # åœ¨è®­ç»ƒç»“æŸæ—¶ä¿å­˜æœ€ç»ˆæœ€ä½³ä¸ªä½“
        if auto_save_best and output_dir and self.best_individual is not None:
            final_best_path = output_dir / "best_individual.npy"
            np.save(final_best_path, self.best_individual)
            print(f"ğŸ’¾ æœ€ç»ˆæœ€ä½³ä¸ªä½“å·²ä¿å­˜: {final_best_path.name} (é€‚åº”åº¦: {self.best_fitness:.4f})")
        
        # æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“
        final_results = {
            'best_fitness': self.best_fitness,
            'best_individual': self.best_individual,
            'final_generation': self.generation,
            'total_time': total_time,
            'fitness_history': self.fitness_history
        }
        
        if hasattr(self, 'progress_monitor') and self.progress_monitor:
            self.progress_monitor.display_final_summary(final_results)
        else:
            print(f"\nè®­ç»ƒå®Œæˆ!")
            print(f"æ€»ä»£æ•°: {self.generation}")
            print(f"æœ€ä½³é€‚åº”åº¦: {self.best_fitness:.4f}")
            print(f"æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f}ç§’")
        
        return final_results
    
    def save_checkpoint(self, filepath: str) -> None:
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'generation': self.generation,
            'population': self.gpu_manager.to_cpu(self.population),
            'fitness_scores': self.gpu_manager.to_cpu(self.fitness_scores),
            'best_fitness': self.best_fitness,
            'best_avg_fitness': self.best_avg_fitness,
            'best_individual': self.best_individual,
            'fitness_history': self.fitness_history,
            'no_improvement_count': self.no_improvement_count,
            'config': self.config
        }
        torch.save(checkpoint, filepath)
        print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {filepath}")
    
    def load_checkpoint(self, filepath: str) -> None:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(filepath, map_location='cpu', weights_only=False)
        
        self.generation = checkpoint['generation']
        self.population = self.gpu_manager.to_gpu(checkpoint['population'])
        self.fitness_scores = self.gpu_manager.to_gpu(checkpoint['fitness_scores'])
        self.best_fitness = checkpoint['best_fitness']
        self.best_avg_fitness = checkpoint['best_avg_fitness']
        self.best_individual = checkpoint['best_individual']
        self.fitness_history = checkpoint['fitness_history']
        self.no_improvement_count = checkpoint['no_improvement_count']
        
        print(f"æ£€æŸ¥ç‚¹å·²åŠ è½½: {filepath}")
        print(f"æ¢å¤åˆ°ç¬¬ {self.generation} ä»£ï¼Œæœ€ä½³é€‚åº”åº¦: {self.best_fitness:.4f}")


if __name__ == "__main__":
    # æµ‹è¯•CUDAé—ä¼ ç®—æ³•
    print("=== CUDAé—ä¼ ç®—æ³•æµ‹è¯• ===")
    
    from cuda_gpu_utils import get_cuda_gpu_manager
    from pathlib import Path

    # åˆå§‹åŒ–GPUç®¡ç†å™¨
    gpu_manager = get_cuda_gpu_manager()

    # å®šä¹‰è¾“å‡ºç›®å½•å’Œæ£€æŸ¥ç‚¹ç›®å½•
    output_dir = Path("results")
    checkpoint_dir = Path("results/checkpoints")
    output_dir.mkdir(parents=True, exist_ok=True)
    checkpoint_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = CudaGAConfig(
        population_size=100,
        max_generations=5,
        feature_dim=50,
        batch_size=500
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    n_samples = 1000
    features = np.random.randn(n_samples, config.feature_dim).astype(np.float32)
    labels = np.random.randn(n_samples).astype(np.float32) * 0.01  # æ¨¡æ‹Ÿä»·æ ¼å˜åŒ–
    
    print(f"æµ‹è¯•æ•°æ®: features {features.shape}, labels {labels.shape}")
    
    # åˆå§‹åŒ–é—ä¼ ç®—æ³•
    ga = CudaGPUAcceleratedGA(config, gpu_manager)
    ga.initialize_population(seed=42)
    
    # è¿è¡Œæµ‹è¯•
    start_time = time.time()
    results = ga.evolve(features, labels, output_dir=output_dir, checkpoint_dir=checkpoint_dir)
    test_time = time.time() - start_time
    
    print(f"\næµ‹è¯•å®Œæˆ!")
    print(f"æœ€ä½³é€‚åº”åº¦: {results['best_fitness']:.4f}")
    print(f"æ€»ä»£æ•°: {results['final_generation']}")
    print(f"æµ‹è¯•æ—¶é—´: {test_time:.2f}ç§’")
    print("CUDAé—ä¼ ç®—æ³•æµ‹è¯•å®Œæˆï¼")
