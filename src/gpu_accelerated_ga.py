"""
Windowsç‰ˆGPUåŠ é€Ÿé—ä¼ ç®—æ³•æ¨¡å—
ä½¿ç”¨DirectMLåç«¯å®ç°AMD GPUåŠ é€Ÿ
"""

import torch
import json
import numpy as np
from typing import Tuple, Optional, Dict, Any
import time
from dataclasses import dataclass
from pathlib import Path
from tqdm import tqdm


from gpu_utils import WindowsGPUManager, get_windows_gpu_manager

@dataclass
class WindowsGAConfig:
    """Windowsé—ä¼ ç®—æ³•é…ç½®"""
    population_size: int = 500  # Windowsä¸Šå»ºè®®è¾ƒå°çš„ç§ç¾¤
    gene_length: int = 1405  # 1400ç‰¹å¾æƒé‡ + 5é£é™©å‚æ•°
    feature_dim: int = 1400
    mutation_rate: float = 0.01
    crossover_rate: float = 0.8
    elite_ratio: float = 0.1
    tournament_size: int = 5
    max_generations: int = 500  # Windowsä¸Šå»ºè®®è¾ƒå°‘ä»£æ•°
    early_stop_patience: int = 30
    
    # Windows GPUä¼˜åŒ–å‚æ•°
    batch_size: int = 500
    use_mixed_precision: bool = False  # DirectMLæ··åˆç²¾åº¦æ”¯æŒæœ‰é™
    memory_efficient: bool = True


class WindowsGPUAcceleratedGA:
    """Windows GPUåŠ é€Ÿçš„é—ä¼ ç®—æ³•"""
    
    def __init__(self, config: WindowsGAConfig, gpu_manager: Optional[WindowsGPUManager] = None):
        """
        åˆå§‹åŒ–Windows GPUåŠ é€Ÿé—ä¼ ç®—æ³•
        
        Args:
            config: é—ä¼ ç®—æ³•é…ç½®
            gpu_manager: GPUç®¡ç†å™¨ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨å…¨å±€ç®¡ç†å™¨
        """
        self.config = config
        self.gpu_manager = gpu_manager or get_windows_gpu_manager()
        self.device = self.gpu_manager.device
        
        # åˆå§‹åŒ–ç§ç¾¤
        self.population = None
        self.fitness_scores = None
        self.best_individual = None
        self.best_fitness = float('-inf')
        self.generation = 0
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'generation_times': [],
            'fitness_times': [],
            'genetic_op_times': [],
            'memory_usage': []
        }
        
        self._initialize_memory_pools()
        print("--- WindowsGPUAcceleratedGAé…ç½® ---")
        print(f"ç§ç¾¤å¤§å°: {config.population_size}")
        print(f"åŸºå› é•¿åº¦: {config.gene_length}")
        print(f"ç‰¹å¾ç»´åº¦: {config.feature_dim}")
        print(f"å˜å¼‚ç‡: {config.mutation_rate}")
        print(f"äº¤å‰ç‡: {config.crossover_rate}")
        print(f"ç²¾è‹±æ¯”ä¾‹: {config.elite_ratio}")
        print(f"é”¦æ ‡èµ›å¤§å°: {config.tournament_size}")
        print(f"è®¾å¤‡: {self.device}")
        print("----------------------------------")
    
    def _initialize_memory_pools(self):
        """åˆå§‹åŒ–å†…å­˜æ± """
        if self.device.type == 'privateuseone':  # DirectMLè®¾å¤‡
            # é¢„åˆ†é…ä¸»è¦æ•°æ®ç»“æ„çš„å†…å­˜
            self.gpu_manager.create_memory_pool(
                'population', 
                (self.config.population_size, self.config.gene_length),
                torch.float32
            )
            
            self.gpu_manager.create_memory_pool(
                'fitness_scores',
                (self.config.population_size,),
                torch.float32
            )
            
            print("Windows GPUå†…å­˜æ± åˆå§‹åŒ–å®Œæˆ")
    
    def initialize_population(self, seed: Optional[int] = None) -> torch.Tensor:
        """
        åˆå§‹åŒ–ç§ç¾¤
        
        Args:
            seed: éšæœºç§å­
            
        Returns:
            åˆå§‹åŒ–çš„ç§ç¾¤å¼ é‡
        """
        if seed is not None:
            torch.manual_seed(seed)
            np.random.seed(seed)
        
        # åœ¨GPUä¸Šç›´æ¥ç”Ÿæˆéšæœºç§ç¾¤
        population = torch.randn(
            self.config.population_size, 
            self.config.gene_length,
            device=self.device,
            dtype=torch.float32
        )
        
        # åˆå§‹åŒ–æƒé‡éƒ¨åˆ† (å‰1400ç»´)
        population[:, :self.config.feature_dim] *= 0.1  # å°çš„åˆå§‹æƒé‡
        
        # åˆå§‹åŒ–å†³ç­–é˜ˆå€¼ (1400-1402ç»´)
        population[:, self.config.feature_dim:self.config.feature_dim+2] = torch.rand(
            self.config.population_size, 2, device=self.device
        ) * 0.1 + 0.01  # é˜ˆå€¼èŒƒå›´ [0.01, 0.11]
        
        # åˆå§‹åŒ–é£é™©å‚æ•° (1402-1405ç»´)
        # æ­¢æŸæ¯”ä¾‹ [0.02, 0.08]
        population[:, self.config.feature_dim+2] = torch.rand(
            self.config.population_size, device=self.device
        ) * 0.06 + 0.02
        
        # æœ€å¤§ä»“ä½æ¯”ä¾‹ [0.2, 0.8]
        population[:, self.config.feature_dim+3] = torch.rand(
            self.config.population_size, device=self.device
        ) * 0.6 + 0.2
        
        # æœ€å¤§å›æ’¤é™åˆ¶ [0.05, 0.15]
        population[:, self.config.feature_dim+4] = torch.rand(
            self.config.population_size, device=self.device
        ) * 0.1 + 0.05
        
        self.population = population
        print(f"ç§ç¾¤åˆå§‹åŒ–å®Œæˆ: {population.shape}")
        return population
    
    def batch_fitness_evaluation(self, features: torch.Tensor, prices: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        æ‰¹é‡é€‚åº”åº¦è¯„ä¼° (Windows GPUåŠ é€Ÿ)
        
        Args:
            features: ç‰¹å¾çŸ©é˜µ (n_samples, feature_dim)
            prices: ä»·æ ¼åºåˆ— (n_samples,)
            
        Returns:
            ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å« (é€‚åº”åº¦åˆ†æ•°, å¤æ™®æ¯”ç‡, ç´¢æè¯ºæ¯”ç‡)
        """
        start_time = time.time()
        
        # ç¡®ä¿æ•°æ®åœ¨GPUä¸Š
        if features.device != self.device:
            features = features.to(self.device)
        if prices.device != self.device:
            prices = prices.to(self.device)
        
        # æå–åŸºå› ç»„ä»¶
        weights = self.population[:, :self.config.feature_dim]  # (pop_size, 1400)
        buy_threshold = self.population[:, self.config.feature_dim]  # (pop_size,)
        sell_threshold = self.population[:, self.config.feature_dim + 1]  # (pop_size,)
        stop_loss = self.population[:, self.config.feature_dim + 2]  # (pop_size,)
        max_position = self.population[:, self.config.feature_dim + 3]  # (pop_size,)
        max_drawdown = self.population[:, self.config.feature_dim + 4]  # (pop_size,)
        
        # æ‰¹é‡è®¡ç®—å†³ç­–åˆ†æ•° (GPUçŸ©é˜µä¹˜æ³•)
        # scores: (pop_size, n_samples)
        scores = torch.mm(weights, features.T)
        
        # å‘é‡åŒ–äº¤æ˜“ä¿¡å·ç”Ÿæˆ
        buy_signals = scores > buy_threshold.unsqueeze(1)
        sell_signals = scores < -sell_threshold.unsqueeze(1)
        
        # æ‰¹é‡å›æµ‹è®¡ç®— (Windowsä¼˜åŒ–ç‰ˆæœ¬)
        fitness_scores_tuple = self._vectorized_backtest_windows(
            buy_signals, sell_signals, prices, 
            stop_loss, max_position, max_drawdown, self.generation
        )
        
        self.fitness_scores = fitness_scores_tuple[0]
        self.stats['fitness_times'].append(time.time() - start_time)
        
        return fitness_scores_tuple
    
    def _vectorized_backtest_windows(self, buy_signals: torch.Tensor, sell_signals: torch.Tensor, 
                                   prices: torch.Tensor, stop_loss: torch.Tensor,
                                   max_position: torch.Tensor, max_drawdown: torch.Tensor, generation: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Windowsä¼˜åŒ–çš„å‘é‡åŒ–å›æµ‹è®¡ç®— (å†…å­˜ä¼˜åŒ–ç‰ˆ)
        
        Args:
            buy_signals: ä¹°å…¥ä¿¡å· (pop_size, n_samples)
            sell_signals: å–å‡ºä¿¡å· (pop_size, n_samples)
            prices: ä»·æ ¼åºåˆ— (n_samples,)
            stop_loss: æ­¢æŸæ¯”ä¾‹ (pop_size,)
            max_position: æœ€å¤§ä»“ä½ (pop_size,)
            max_drawdown: æœ€å¤§å›æ’¤ (pop_size,)
            
        Returns:
            ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å« (é€‚åº”åº¦åˆ†æ•°, å¤æ™®æ¯”ç‡, ç´¢æè¯ºæ¯”ç‡)
        """
        pop_size, n_samples = buy_signals.shape
        
        # åˆå§‹åŒ–çŠ¶æ€
        positions = torch.zeros(pop_size, device=self.device)
        equity = torch.ones(pop_size, device=self.device)
        peak_equity = torch.ones(pop_size, device=self.device)
        
        # å†…å­˜ä¼˜åŒ–ï¼šä¸ä¿å­˜å®Œæ•´çš„æ”¶ç›Šåºåˆ—ï¼Œè€Œæ˜¯è®¡ç®—ç»Ÿè®¡æ•°æ®
        sum_returns = torch.zeros(pop_size, device=self.device)
        sum_sq_returns = torch.zeros(pop_size, device=self.device)
        downside_sum_sq_returns = torch.zeros(pop_size, device=self.device) # ç”¨äºç´¢æè¯ºæ¯”ç‡
        trade_counts = torch.zeros(pop_size, device=self.device)

        # é¢„è®¡ç®—ä»·æ ¼å˜åŒ–ç‡
        price_changes = (prices[1:] - prices[:-1]) / prices[:-1]
        price_changes = torch.cat([torch.zeros(1, device=self.device), price_changes]) # è¡¥å…¨ç¬¬ä¸€ä¸ªä¸º0

        # Windowsä¼˜åŒ–ï¼šåˆ†å—å¤„ç†ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
        chunk_size = min(1000, n_samples)
        
        # ä¸ºå›æµ‹æ•°æ®å—æ·»åŠ å†…å±‚tqdmè¿›åº¦æ¡
        backtest_progress = tqdm(range(1, n_samples, chunk_size), desc=f"ç¬¬ {generation} ä»£ å›æµ‹", leave=True)

        for chunk_start in backtest_progress:
            chunk_end = min(chunk_start + chunk_size, n_samples)
            
            for t in range(chunk_start, chunk_end):
                price_change = price_changes[t]
                
                # è®¡ç®—å½“å‰æ”¶ç›Š
                period_return = positions * price_change
                equity += period_return
                
                # æ›´æ–°ç»Ÿè®¡æ•°æ®
                sum_returns += period_return
                sum_sq_returns += period_return.pow(2)
                downside_sum_sq_returns += torch.where(period_return < 0, period_return.pow(2), torch.zeros_like(period_return))

                # æ›´æ–°å†å²æœ€é«˜å‡€å€¼
                peak_equity = torch.maximum(peak_equity, equity)
                
                # è®¡ç®—å½“å‰å›æ’¤
                current_drawdown = (peak_equity - equity) / peak_equity
                
                # é£é™©æ§åˆ¶ï¼šå¼ºåˆ¶å¹³ä»“
                force_close = current_drawdown > max_drawdown
                positions = torch.where(force_close, torch.zeros_like(positions), positions)
                
                # æ­¢æŸæ£€æŸ¥
                stop_loss_trigger = (positions > 0) & (price_change < -stop_loss)
                positions = torch.where(stop_loss_trigger, torch.zeros_like(positions), positions)
                
                # äº¤æ˜“ä¿¡å·å¤„ç†
                can_buy = (positions == 0) & buy_signals[:, t] & (~force_close)
                new_position = torch.where(can_buy, max_position, positions)
                
                can_sell = (positions > 0) & sell_signals[:, t]
                new_position = torch.where(can_sell, torch.zeros_like(positions), new_position)
                
                # ç»Ÿè®¡äº¤æ˜“æ¬¡æ•°
                trade_counts += (new_position != positions).float()
                
                positions = new_position
            
            if chunk_start % (chunk_size * 5) == 0:
                self.gpu_manager.clear_cache()
        
        # è®¡ç®—é€‚åº”åº¦æŒ‡æ ‡
        fitness_metrics = self._calculate_fitness_metrics_windows(
            sum_returns, sum_sq_returns, downside_sum_sq_returns, trade_counts, n_samples, equity, peak_equity
        )
        
        return fitness_metrics
    
    def _calculate_fitness_metrics_windows(self, sum_returns: torch.Tensor, sum_sq_returns: torch.Tensor, 
                                         downside_sum_sq_returns: torch.Tensor, 
                                         trade_counts: torch.Tensor, n_samples: int, 
                                         equity: torch.Tensor, peak_equity: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Windowsä¼˜åŒ–çš„é€‚åº”åº¦æŒ‡æ ‡è®¡ç®— (å†…å­˜ä¼˜åŒ–ç‰ˆ)

        Args:
            sum_returns: æ€»æ”¶ç›Š
            sum_sq_returns: æ”¶ç›Šå¹³æ–¹å’Œ
            trade_counts: äº¤æ˜“æ¬¡æ•°
            n_samples: æ ·æœ¬æ€»æ•°
            equity: æœ€ç»ˆå‡€å€¼
            peak_equity: å†å²æœ€é«˜å‡€å€¼

        Returns:
            ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å« (ç»¼åˆé€‚åº”åº¦åˆ†æ•°, å¤æ™®æ¯”ç‡, ç´¢æè¯ºæ¯”ç‡)
        """
        # è®¡ç®—å¤æ™®ç‡
        mean_returns = sum_returns / n_samples
        variance = sum_sq_returns / n_samples - mean_returns.pow(2)
        variance = torch.clamp(variance, min=0)
        std_returns = torch.sqrt(variance)
        sharpe_ratios = mean_returns / (std_returns + 1e-9) * np.sqrt(252)

        # è®¡ç®—æœ€å¤§å›æ’¤
        max_drawdowns = (peak_equity - equity) / peak_equity

        # è®¡ç®—äº¤æ˜“é¢‘ç‡ç¨³å®šæ€§
        stability_scores = 1.0 / (1.0 + trade_counts / n_samples)

        # è®¡ç®—ç´¢æè¯ºæ¯”ç‡
        downside_variance = downside_sum_sq_returns / n_samples
        downside_variance = torch.clamp(downside_variance, min=0)
        downside_std = torch.sqrt(downside_variance)
        sortino_ratios = mean_returns / (downside_std + 1e-9) * np.sqrt(252)

        # ç»¼åˆé€‚åº”åº¦å‡½æ•°
        fitness = (0.5 * sharpe_ratios -
                   0.3 * max_drawdowns +
                   0.2 * stability_scores)

        # ä½¿ç”¨ torch.nan_to_num æ›¿æ¢æ‰€æœ‰ NaN
        fitness = torch.nan_to_num(fitness, nan=-1e9) # å°†NaNæ›¿æ¢ä¸ºä¸€ä¸ªéå¸¸å°çš„å€¼
        sharpe_ratios = torch.nan_to_num(sharpe_ratios, nan=0.0)
        sortino_ratios = torch.nan_to_num(sortino_ratios, nan=0.0)

        return fitness, sharpe_ratios, sortino_ratios
    
    def tournament_selection(self, tournament_size: Optional[int] = None) -> torch.Tensor:
        """
        é”¦æ ‡èµ›é€‰æ‹© (Windows GPUåŠ é€Ÿ)
        
        Args:
            tournament_size: é”¦æ ‡èµ›å¤§å°
            
        Returns:
            é€‰ä¸­çš„ä¸ªä½“ç´¢å¼•
        """
        if tournament_size is None:
            tournament_size = self.config.tournament_size
        
        pop_size = self.config.population_size
        
        # éšæœºé€‰æ‹©é”¦æ ‡èµ›å‚ä¸è€…
        tournament_indices = torch.randint(
            0, pop_size, 
            (pop_size, tournament_size),
            device=self.device
        )
        
        # è·å–å‚ä¸è€…çš„é€‚åº”åº¦
        tournament_fitness = self.fitness_scores[tournament_indices]
        
        # é€‰æ‹©æ¯ä¸ªé”¦æ ‡èµ›çš„è·èƒœè€…
        winners = torch.argmax(tournament_fitness, dim=1)
        selected_indices = tournament_indices[torch.arange(pop_size), winners]
        
        return selected_indices
    
    def crossover_and_mutation(self, parent_indices: torch.Tensor) -> torch.Tensor:
        """
        äº¤å‰å’Œå˜å¼‚æ“ä½œ (Windows GPUåŠ é€Ÿ)
        
        Args:
            parent_indices: çˆ¶ä»£ä¸ªä½“ç´¢å¼•
            
        Returns:
            æ–°ä¸€ä»£ç§ç¾¤
        """
        start_time = time.time()
        
        pop_size = self.config.population_size
        new_population = torch.zeros_like(self.population)
        
        # ç²¾è‹±ä¿ç•™
        elite_count = int(pop_size * self.config.elite_ratio)
        # ç¡®ä¿è‡³å°‘ä¿ç•™ä¸€ä¸ªä¸ªä½“ï¼Œé¿å…k=0çš„è¾¹ç•Œæƒ…å†µ
        if elite_count == 0 and pop_size > 0:
            elite_count = 1
        

        
        # äº¤å‰æ“ä½œ (Windowsä¼˜åŒ–ï¼šåˆ†æ‰¹å¤„ç†)

        elite_indices = torch.topk(self.fitness_scores, elite_count).indices
        new_population[:elite_count] = self.population[elite_indices]
        
        # äº¤å‰æ“ä½œ (Windowsä¼˜åŒ–ï¼šåˆ†æ‰¹å¤„ç†)""
        
        # äº¤å‰æ“ä½œ (Windowsä¼˜åŒ–ï¼šåˆ†æ‰¹å¤„ç†)
        batch_size = self.config.batch_size
        for i in range(elite_count, pop_size, batch_size):
            end_idx = min(i + batch_size, pop_size)
            batch_size_actual = end_idx - i
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡
            for j in range(0, batch_size_actual, 2):
                idx1, idx2 = i + j, min(i + j + 1, pop_size - 1)
                
                parent1_idx = parent_indices[idx1]
                parent2_idx = parent_indices[idx2]
                
                if torch.rand(1, device=self.device) < self.config.crossover_rate:
                    # å‡åŒ€äº¤å‰
                    mask = torch.rand(self.config.gene_length, device=self.device) < 0.5
                    
                    child1 = torch.where(mask, 
                                       self.population[parent1_idx], 
                                       self.population[parent2_idx])
                    child2 = torch.where(mask, 
                                       self.population[parent2_idx], 
                                       self.population[parent1_idx])
                else:
                    child1 = self.population[parent1_idx].clone()
                    child2 = self.population[parent2_idx].clone()
                
                new_population[idx1] = child1
                if idx2 < pop_size:
                    new_population[idx2] = child2
            
            # Windowsä¼˜åŒ–ï¼šå®šæœŸæ¸…ç†å†…å­˜
            if i % (batch_size * 4) == 0:
                self.gpu_manager.clear_cache()
        
        # å˜å¼‚æ“ä½œ
        mutation_mask = torch.rand(pop_size, self.config.gene_length, device=self.device) < self.config.mutation_rate
        mutation_values = torch.randn(pop_size, self.config.gene_length, device=self.device) * 0.01
        
        new_population[elite_count:] += mutation_mask[elite_count:] * mutation_values[elite_count:]
        
        # çº¦æŸé£é™©å‚æ•°èŒƒå›´
        self._constrain_risk_parameters(new_population)
        
        self.population = new_population
        self.stats['genetic_op_times'].append(time.time() - start_time)
        
        return new_population
    
    def _constrain_risk_parameters(self, population: torch.Tensor):
        """çº¦æŸé£é™©å‚æ•°åˆ°åˆç†èŒƒå›´"""
        # å†³ç­–é˜ˆå€¼ [0.001, 0.2]
        population[:, self.config.feature_dim:self.config.feature_dim+2] = torch.clamp(
            population[:, self.config.feature_dim:self.config.feature_dim+2], 0.001, 0.2
        )
        
        # æ­¢æŸæ¯”ä¾‹ [0.01, 0.1]
        population[:, self.config.feature_dim+2] = torch.clamp(
            population[:, self.config.feature_dim+2], 0.01, 0.1
        )
        
        # æœ€å¤§ä»“ä½ [0.1, 1.0]
        population[:, self.config.feature_dim+3] = torch.clamp(
            population[:, self.config.feature_dim+3], 0.1, 1.0
        )
        
        # æœ€å¤§å›æ’¤ [0.02, 0.3]
        population[:, self.config.feature_dim+4] = torch.clamp(
            population[:, self.config.feature_dim+4], 0.02, 0.3
        )
    
    def evolve_one_generation(self, features: torch.Tensor, prices: torch.Tensor) -> Dict[str, float]:
        """
        è¿›åŒ–ä¸€ä»£ (Windowsä¼˜åŒ–ç‰ˆæœ¬)
        
        Args:
            features: ç‰¹å¾çŸ©é˜µ
            prices: ä»·æ ¼åºåˆ—
            
        Returns:
            å½“ä»£ç»Ÿè®¡ä¿¡æ¯
        """
        gen_start_time = time.time()
        
        # é€‚åº”åº¦è¯„ä¼°
        fitness_scores, sharpe_ratios, sortino_ratios = self.batch_fitness_evaluation(features, prices)
        
        # æ›´æ–°æœ€ä¼˜ä¸ªä½“
        best_idx = torch.argmax(fitness_scores).item()
        current_best_fitness = fitness_scores[best_idx].item()
        
        if current_best_fitness > self.best_fitness:
            self.best_fitness = current_best_fitness
            self.best_individual = self.population[best_idx].clone()
        
        # é€‰æ‹©
        parent_indices = self.tournament_selection()
        
        # äº¤å‰å’Œå˜å¼‚
        self.crossover_and_mutation(parent_indices)
        
        self.generation += 1
        
        # ç»Ÿè®¡ä¿¡æ¯
        gen_time = time.time() - gen_start_time
        self.stats['generation_times'].append(gen_time)
        
        used_memory, total_memory = self.gpu_manager.get_memory_usage()
        self.stats['memory_usage'].append(used_memory)
        
        # Windowsä¼˜åŒ–ï¼šå®šæœŸæ¸…ç†å†…å­˜
        if self.generation % 5 == 0:
            self.gpu_manager.clear_cache()
        
        stats = {
            'generation': self.generation,
            'best_fitness': current_best_fitness,
            'mean_fitness': torch.mean(fitness_scores).item(),
            'std_fitness': torch.std(fitness_scores).item(),
            'generation_time': gen_time,
            'system_memory_gb': used_memory,
            'mean_sharpe_ratio': torch.mean(sharpe_ratios).item(),
            'mean_sortino_ratio': torch.mean(sortino_ratios).item()
        }
        
        return stats
    
    def evolve(self, features: torch.Tensor, prices: torch.Tensor,
               save_checkpoints: bool = False, checkpoint_dir: Optional[Path] = None,
               checkpoint_interval: int = 50, continuous_training: bool = False,
               save_generation_results: bool = False, generation_log_file: Optional[Path] = None,
               generation_log_interval: int = 1, auto_save_best: bool = False,
               output_dir: Optional[Path] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œé—ä¼ ç®—æ³•è¿›åŒ–è¿‡ç¨‹

        Args:
            features: ç‰¹å¾çŸ©é˜µ
            prices: ä»·æ ¼åºåˆ—
            save_checkpoints: æ˜¯å¦ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
            checkpoint_interval: æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”
            continuous_training: æ˜¯å¦å¯ç”¨æŒç»­è®­ç»ƒæ¨¡å¼
            save_generation_results: æ˜¯å¦æ¯ä»£ä¿å­˜ç»“æœ
            generation_log_file: æ¯ä»£ç»“æœæ—¥å¿—æ–‡ä»¶è·¯å¾„
            generation_log_interval: æ¯éš”å¤šå°‘ä»£è®°å½•åˆ°æ–‡ä»¶
            auto_save_best: æ˜¯å¦è‡ªåŠ¨ä¿å­˜æœ€ä½³ä¸ªä½“
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            åŒ…å«è®­ç»ƒç»“æœçš„å­—å…¸
        """
        total_start_time = time.time()
        fitness_history = []
        no_improvement_count = 0
        last_best_fitness = self.best_fitness
        
        # æ³¨æ„ï¼šç§ç¾¤åˆå§‹åŒ–ç°åœ¨ç”±å¤–éƒ¨è°ƒç”¨è€…ï¼ˆå¦‚main.pyï¼‰å¤„ç†
        if self.population is None:
            tqdm.write("é”™è¯¯ï¼šç§ç¾¤æœªåˆå§‹åŒ–ï¼Œè¯·åœ¨è°ƒç”¨evolveä¹‹å‰è°ƒç”¨initialize_populationæˆ–load_checkpoint")
            raise ValueError("Population not initialized")

        print("--- å¼€å§‹è¿›åŒ– ---")
        print(f"è¾“å…¥ç‰¹å¾å½¢çŠ¶: {features.shape}")
        print(f"è¾“å…¥ä»·æ ¼å½¢çŠ¶: {prices.shape}")
        print(f"æŒç»­è®­ç»ƒæ¨¡å¼: {'å¯ç”¨' if continuous_training else 'ç¦ç”¨'}")
        print(f"æ¯ä»£ç»“æœè®°å½•: {'å¯ç”¨' if save_generation_results else 'ç¦ç”¨'}")
        if generation_log_file:
            print(f"ç»“æœæ—¥å¿—æ–‡ä»¶: {generation_log_file}")
        print("------------------")

        # ä»å·²åŠ è½½çš„ä»£æ•°å¼€å§‹ï¼Œæˆ–ä»0å¼€å§‹
        start_gen = self.generation
        
        # ç¡®å®šæœ€å¤§ä»£æ•°
        if continuous_training and self.config.max_generations == -1:
            max_generations = float('inf')
            print("ğŸ”„ æŒç»­è®­ç»ƒæ¨¡å¼ï¼šå°†æ— é™æœŸè®­ç»ƒï¼ŒæŒ‰Ctrl+Cåœæ­¢")
        else:
            max_generations = self.config.max_generations

        # åˆå§‹åŒ–æ¯ä»£ç»“æœè®°å½•
        def save_generation_log(stats_data):
            """ä¿å­˜æ¯ä»£ç»“æœåˆ°æ—¥å¿—æ–‡ä»¶"""
            if save_generation_results and generation_log_file:
                try:
                    # æ·»åŠ æ—¶é—´æˆ³
                    stats_data['timestamp'] = time.strftime("%Y-%m-%d %H:%M:%S")
                    
                    # ä»¥è¿½åŠ æ¨¡å¼å†™å…¥JSONLæ ¼å¼
                    with open(generation_log_file, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(stats_data, ensure_ascii=False) + '\n')
                except Exception as e:
                    tqdm.write(f"è­¦å‘Šï¼šä¿å­˜æ¯ä»£ç»“æœå¤±è´¥: {e}")

        # ä¸»è®­ç»ƒå¾ªç¯
        gen = start_gen
        try:
            while gen < max_generations:
                stats = self.evolve_one_generation(features, prices)
                fitness_history.append(stats)
                
                # é‡æ–°åŠ å…¥æ—¥å¿—è®°å½•
                tqdm.write(f"ç¬¬ {stats['generation']} ä»£: æœ€ä½³é€‚åº”åº¦={stats['best_fitness']:.4f}, "
                           f"å¹³å‡é€‚åº”åº¦={stats['mean_fitness']:.4f}, "
                           f"å¤æ™®æ¯”ç‡={stats['mean_sharpe_ratio']:.4f}, "
                           f"ç´¢æè¯ºæ¯”ç‡={stats['mean_sortino_ratio']:.4f}, "
                           f"ç”¨æ—¶={stats['generation_time']:.2f}ç§’, "
                           f"å†…å­˜={stats['system_memory_gb']:.2f}GB")
                
                # æ¯ä»£ç»“æœè®°å½•
                if save_generation_results and stats['generation'] % generation_log_interval == 0:
                    save_generation_log(stats)
                
                # è‡ªåŠ¨ä¿å­˜æœ€ä½³ä¸ªä½“
                if auto_save_best and output_dir and stats['best_fitness'] > last_best_fitness:
                    try:
                        best_path = output_dir / f"best_individual_gen_{stats['generation']}.npy"
                        np.save(best_path, self.gpu_manager.to_cpu(self.best_individual))
                        tqdm.write(f"ğŸ’¾ æ–°æœ€ä½³ä¸ªä½“å·²ä¿å­˜: {best_path}")
                        last_best_fitness = stats['best_fitness']
                    except Exception as e:
                        tqdm.write(f"è­¦å‘Šï¼šä¿å­˜æœ€ä½³ä¸ªä½“å¤±è´¥: {e}")
                
                # æ£€æŸ¥æ—©æœŸåœæ­¢ï¼ˆä»…åœ¨éæŒç»­è®­ç»ƒæ¨¡å¼ä¸‹ï¼‰
                if not continuous_training:
                    if stats['best_fitness'] > self.best_fitness:
                        self.best_fitness = stats['best_fitness']
                        no_improvement_count = 0
                    else:
                        no_improvement_count += 1
                    
                    if no_improvement_count >= self.config.early_stop_patience:
                        tqdm.write(f"è¿ç»­{self.config.early_stop_patience}ä»£æ²¡æœ‰æ”¹è¿›ï¼Œæå‰åœæ­¢ã€‚")
                        break
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if save_checkpoints and checkpoint_dir and (gen + 1) % checkpoint_interval == 0:
                    checkpoint_dir.mkdir(parents=True, exist_ok=True)
                    checkpoint_path = checkpoint_dir / f"checkpoint_gen_{gen+1}.pt"
                    self.save_checkpoint(str(checkpoint_path))
                
                gen += 1
                
        except KeyboardInterrupt:
            tqdm.write("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
            if continuous_training:
                tqdm.write("æŒç»­è®­ç»ƒå·²åœæ­¢")
        
        total_time = time.time() - total_start_time
        tqdm.write(f"é—ä¼ ç®—æ³•è¿›åŒ–å®Œæˆï¼Œæ€»ç”¨æ—¶: {total_time:.2f}ç§’")
        
        return {
            'best_individual': self.gpu_manager.to_cpu(self.best_individual),
            'best_fitness': self.best_fitness,
            'fitness_history': fitness_history,
            'total_time': total_time,
            'final_generation': self.generation
        }
    
    def get_best_individual(self) -> Tuple[torch.Tensor, float]:
        """
        è·å–æœ€ä¼˜ä¸ªä½“
        
        Returns:
            (æœ€ä¼˜ä¸ªä½“åŸºå› , æœ€ä¼˜é€‚åº”åº¦)
        """
        return self.best_individual, self.best_fitness
    
    def save_checkpoint(self, filepath: str):
        """
        ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹
        """
        checkpoint = {
            'generation': self.generation,
            'population': self.gpu_manager.to_cpu(self.population),
            'best_individual': self.gpu_manager.to_cpu(self.best_individual) if self.best_individual is not None else None,
            'best_fitness': self.best_fitness,
            'config': self.config,
            'stats': self.stats
        }
        torch.save(checkpoint, filepath)
        tqdm.write(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {filepath}")
    
    def load_checkpoint(self, filepath: str):
        """
        åŠ è½½è®­ç»ƒæ£€æŸ¥ç‚¹
        """
        checkpoint = torch.load(filepath, map_location='cpu')
        
        self.generation = checkpoint['generation']
        self.population = self.gpu_manager.to_gpu(checkpoint['population'])
        self.best_individual = self.gpu_manager.to_gpu(checkpoint['best_individual']) if checkpoint['best_individual'] is not None else None
        self.best_fitness = checkpoint['best_fitness']
        self.stats = checkpoint['stats']
        
        tqdm.write(f"æ£€æŸ¥ç‚¹å·²åŠ è½½: {filepath}, ä»£æ•°: {self.generation}")


if __name__ == "__main__":
    # æµ‹è¯•Windows GPUåŠ é€Ÿé—ä¼ ç®—æ³•
    print("=== Windows GPUåŠ é€Ÿé—ä¼ ç®—æ³•æµ‹è¯• ===")
    
    # é…ç½®
    config = WindowsGAConfig(
        population_size=50,  # å°è§„æ¨¡æµ‹è¯•
        max_generations=5
    )
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    n_samples = 1000
    features = torch.randn(n_samples, config.feature_dim)
    prices = torch.cumsum(torch.randn(n_samples) * 0.01, dim=0) + 100
    
    # åˆå§‹åŒ–é—ä¼ ç®—æ³•
    ga = WindowsGPUAcceleratedGA(config)
    ga.initialize_population(seed=42)
    
    print(f"ç§ç¾¤å¤§å°: {config.population_size}")
    print(f"åŸºå› é•¿åº¦: {config.gene_length}")
    print(f"ä½¿ç”¨è®¾å¤‡: {ga.device}")
    
    # è¿è¡Œå‡ ä»£è¿›åŒ–
    for gen in range(3):
        stats = ga.evolve_one_generation(features, prices)
        print(f"ç¬¬{stats['generation']}ä»£: "
              f"æœ€ä¼˜é€‚åº”åº¦={stats['best_fitness']:.4f}, "
              f"å¹³å‡é€‚åº”åº¦={stats['mean_fitness']:.4f}, "
              f"ç”¨æ—¶={stats['generation_time']:.2f}s")
    
    print("Windows GPUæµ‹è¯•å®Œæˆï¼")