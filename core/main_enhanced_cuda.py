"""
å¢å¼ºç‰ˆCUDA-accelerated Genetic Algorithm Trading Agent Training
Enhanced CUDA-accelerated Genetic Algorithm with:
1. Data Annealing
2. Multi-Objective Optimization  
3. Enhanced Monitoring
"""

import time
from pathlib import Path
import json
import torch
import numpy as np
import sys
import os
from numpy._core.multiarray import _reconstruct as numpy_reconstruct
from numpy import ndarray as numpy_ndarray

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from cuda_gpu_utils import CudaGPUManager, get_cuda_gpu_manager, check_cuda_compatibility, optimize_cuda_settings
from enhanced_cuda_ga import EnhancedCudaGA, EnhancedGAConfig
from data_annealing_scheduler import AnnealingStrategy
from data_processor import GPUDataProcessor

# æ€§èƒ½åˆ†æ
try:
    from performance_profiler import get_profiler, start_monitoring, stop_monitoring, print_summary, save_report, timer
    PERFORMANCE_PROFILER_AVAILABLE = True
    print("ğŸ” æ€§èƒ½åˆ†æå™¨å·²å¯ç”¨")
except ImportError:
    PERFORMANCE_PROFILER_AVAILABLE = False
    print("âš ï¸  æ€§èƒ½åˆ†æå™¨ä¸å¯ç”¨")
    # åˆ›å»ºç©ºçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    class timer:
        def __init__(self, *args, **kwargs):
            pass
        def __enter__(self):
            return self
        def __exit__(self, *args):
            pass
    def start_monitoring(*args, **kwargs):
        pass
    def stop_monitoring():
        pass
    def print_summary(*args, **kwargs):
        pass
    def save_report(*args, **kwargs):
        pass

# ç¡®ä¿resultsç›®å½•å­˜åœ¨
results_dir = Path('../results')
results_dir.mkdir(exist_ok=True)


def main():
    """Main function - Enhanced CUDA version with advanced features"""
    # Allowlist numpy._core.multiarray._reconstruct and numpy.ndarray for torch.load with weights_only=True
    torch.serialization.add_safe_globals([numpy_reconstruct, numpy_ndarray])

    # ==============================================================================
    # ======================= å¢å¼ºç‰ˆè®­ç»ƒå‚æ•°é…ç½® ============================
    # ==============================================================================
    ENHANCED_TRAINING_CONFIG = {
        # ==================== æ ¸å¿ƒè®­ç»ƒå‚æ•° ====================
        
        # --- æ•°æ®é…ç½® ---
        "data_directory": "../data",     # æ•°æ®æ–‡ä»¶ç›®å½•
        "window_size": 350,             # ç‰¹å¾å·¥ç¨‹çª—å£å¤§å°
        "normalization": "rolling",     # å½’ä¸€åŒ–æ–¹æ³•: 'rolling', 'minmax_local', 'hybrid'
        "batch_size": 1000,             # CUDAä¸Šå¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡
        
        # --- é—ä¼ ç®—æ³•å‚æ•° ---
        "population_size": 3000,         # ç§ç¾¤å¤§å° (å¢å¼ºç‰ˆæ¨è: 2000-5000)
        "generations": -1,              # è®­ç»ƒä»£æ•° (-1=æ— é™è®­ç»ƒ, æ¨è: 200-2000)
        "mutation_rate": 0.01,           # å˜å¼‚ç‡ (æ¨è: 0.005-0.02)
        "crossover_rate": 0.8,           # äº¤å‰ç‡ (æ¨è: 0.7-0.9)
        "elite_ratio": 0.05,              # ç²¾è‹±ä¿ç•™æ¯”ä¾‹ (æ¨è: 0.05-0.15)
        "early_stop_patience": 150,      # æ— æ”¹è¿›åœæ­¢ä»£æ•° (æ¨è: 100-300)
        "use_torch_scan": True,          # ä½¿ç”¨torch.scanä¼˜åŒ–å›æµ‹ (æ¨è: True)
        
        # ==================== å¢å¼ºåŠŸèƒ½é…ç½® ====================
        
        # --- æ•°æ®é€€ç«é…ç½® ---
        "enable_data_annealing": True,           # å¯ç”¨æ•°æ®é€€ç«
        "annealing_strategy": "progressive",    # é€€ç«ç­–ç•¥: 'temporal', 'volatility', 'market_regime', 'feature_complexity', 'progressive'
        "annealing_rate": 0.1,                  # é€€ç«é€Ÿåº¦ (0.05-0.2)
        "min_data_ratio": 0.3,                  # æœ€å°æ•°æ®ä½¿ç”¨æ¯”ä¾‹ (0.2-0.5)
        "max_data_ratio": 1.0,                  # æœ€å¤§æ•°æ®ä½¿ç”¨æ¯”ä¾‹ (é€šå¸¸ä¸º1.0)
        "warmup_generations": 50,               # é¢„çƒ­ä»£æ•° (20-100)
        
        # --- å¤šç›®æ ‡ä¼˜åŒ–é…ç½® ---
        "enable_multi_objective": True,         # å¯ç”¨å¤šç›®æ ‡ä¼˜åŒ–
        "pareto_front_size": 100,               # å¸•ç´¯æ‰˜å‰æ²¿å¤§å° (50-200)
        "enable_hypervolume": True,             # å¯ç”¨è¶…ä½“ç§¯è®¡ç®—
        "objective_weights": {                  # ç›®æ ‡æƒé‡ (æ€»å’Œåº”ä¸º1.0)
            "sharpe_ratio": 0.25,               # å¤æ™®æ¯”ç‡ (æœ€å¤§åŒ–)
            "max_drawdown": 0.20,               # æœ€å¤§å›æ’¤ (æœ€å°åŒ–)
            "total_return": 0.25,               # æ€»æ”¶ç›Šç‡ (æœ€å¤§åŒ–)
            "win_rate": 0.15,                   # èƒœç‡ (æœ€å¤§åŒ–)
            "volatility": 0.10,                 # æ³¢åŠ¨ç‡ (æœ€å°åŒ–)
            "profit_factor": 0.05,              # ç›ˆäºæ¯” (æœ€å¤§åŒ–)
        },
        
        # --- å¢å¼ºç›‘æ§é…ç½® ---
        "enable_enhanced_monitoring": True,     # å¯ç”¨å¢å¼ºç›‘æ§
        "monitoring_save_interval": 10,         # ç›‘æ§ä¿å­˜é—´éš”
        "detailed_logging": True,               # è¯¦ç»†æ—¥å¿—è®°å½•
        "track_diversity": True,                # è·Ÿè¸ªç§ç¾¤å¤šæ ·æ€§
        "track_convergence": True,              # è·Ÿè¸ªæ”¶æ•›æ€§
        "export_format": "both",                # å¯¼å‡ºæ ¼å¼: 'json', 'csv', 'both'
        
        # ==================== CUDAä¸“ç”¨é…ç½® ====================
        
        # --- GPUè®¾ç½® ---
        "gpu_device_id": 0,              # GPUè®¾å¤‡ID (0ä¸ºç¬¬ä¸€ä¸ªGPU)
        "gpu_memory_fraction": 0.9,      # GPUå†…å­˜ä½¿ç”¨æ¯”ä¾‹ (0.0-1.0)
        "mixed_precision": False,        # æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (å®éªŒæ€§)
        
        # ==================== ç³»ç»Ÿé…ç½® ====================
        
        # --- ä¿å­˜è®¾ç½® ---
        "results_dir": "../results",     # ç»“æœè¾“å‡ºç›®å½•
        "save_checkpoints": True,        # æ˜¯å¦ä¿å­˜æ£€æŸ¥ç‚¹
        "checkpoint_interval": 50,       # æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”
        "auto_save_best": True,          # æ˜¯å¦è‡ªåŠ¨ä¿å­˜æœ€ä½³ä¸ªä½“
        "save_best_interval": 100,       # æ¯éš”å¤šå°‘ä»£ä¿å­˜æœ€ä¼˜ä¸ªä½“
        
        # --- æ—¥å¿—è®¾ç½® ---
        "save_generation_results": True, # æ˜¯å¦ä¿å­˜æ¯ä»£ç»“æœ
        "generation_log_interval": 1,    # æ—¥å¿—è®°å½•é—´éš”
    }
    
    # ==============================================================================
    # ======================== é¢„è®¾é…ç½®æ¨¡æ¿ (å¢å¼ºç‰ˆ) =========================
    # ==============================================================================
    
    # ğŸš€ å¿«é€Ÿæµ‹è¯•é…ç½® (å¢å¼ºç‰ˆ)
    QUICK_TEST_CONFIG = {
        **ENHANCED_TRAINING_CONFIG,
        "population_size": 500,
        "generations": 30,
        "checkpoint_interval": 10,
        "batch_size": 500,
        "warmup_generations": 5,
        "pareto_front_size": 50,
        "monitoring_save_interval": 5,
    }
    
    # ğŸ’ª é«˜æ€§èƒ½é…ç½® (é€‚åˆé«˜ç«¯NVIDIA GPU)
    HIGH_PERFORMANCE_CONFIG = {
        **ENHANCED_TRAINING_CONFIG,
        "population_size": 4000,
        "generations": 1000,
        "checkpoint_interval": 100,
        "batch_size": 2000,
        "early_stop_patience": 200,
        "warmup_generations": 100,
        "pareto_front_size": 150,
    }
    
    # ğŸ”¥ æé™æ€§èƒ½é…ç½® (RTX 4090/A100ç­‰)
    EXTREME_PERFORMANCE_CONFIG = {
        **ENHANCED_TRAINING_CONFIG,
        "population_size": 6000,
        "generations": 2000,
        "checkpoint_interval": 50,
        "batch_size": 3000,
        "early_stop_patience": 300,
        "gpu_memory_fraction": 0.95,
        "warmup_generations": 150,
        "pareto_front_size": 200,
    }
    
    # ğŸ›¡ï¸ ä¿å®ˆäº¤æ˜“ç­–ç•¥ (å¢å¼ºç‰ˆ) - æ³¨é‡é£é™©æ§åˆ¶
    CONSERVATIVE_CONFIG = {
        **ENHANCED_TRAINING_CONFIG,
        "objective_weights": {
            "sharpe_ratio": 0.30,           # æ›´é‡è§†é£é™©è°ƒæ•´æ”¶ç›Š
            "max_drawdown": 0.35,           # æ›´é‡è§†å›æ’¤æ§åˆ¶
            "total_return": 0.15,           # é€‚åº¦é‡è§†æ”¶ç›Š
            "volatility": 0.15,             # é‡è§†æ³¢åŠ¨ç‡æ§åˆ¶
            "win_rate": 0.05,               # é€‚åº¦é‡è§†èƒœç‡
        },
        "population_size": 2000,
        "annealing_strategy": "volatility", # ä»ä½æ³¢åŠ¨æ•°æ®å¼€å§‹
        "min_data_ratio": 0.4,              # ä½¿ç”¨æ›´å¤šæ•°æ®
    }
    
    # âš¡ æ¿€è¿›äº¤æ˜“ç­–ç•¥ (å¢å¼ºç‰ˆ) - è¿½æ±‚é«˜æ”¶ç›Š
    AGGRESSIVE_CONFIG = {
        **ENHANCED_TRAINING_CONFIG,
        "objective_weights": {
            "total_return": 0.40,           # é‡è§†æ€»æ”¶ç›Š
            "profit_factor": 0.25,          # é‡è§†ç›ˆäºæ¯”
            "win_rate": 0.20,               # é‡è§†èƒœç‡
            "sharpe_ratio": 0.10,           # é€‚åº¦é‡è§†é£é™©è°ƒæ•´
            "max_drawdown": 0.05,           # è¾ƒå°‘é‡è§†å›æ’¤
        },
        "population_size": 3000,
        "annealing_strategy": "market_regime", # é€‚åº”ä¸åŒå¸‚åœºçŠ¶æ€
        "early_stop_patience": 100,         # æ›´æ¿€è¿›çš„æ—©åœ
    }
    
    # ğŸ”„ é•¿æœŸè®­ç»ƒé…ç½® (å¢å¼ºç‰ˆ)
    LONG_TERM_CONFIG = {
        **ENHANCED_TRAINING_CONFIG,
        "generations": -1,               # æ— é™è®­ç»ƒ
        "early_stop_patience": 300,      # æ›´é•¿çš„è€å¿ƒ
        "checkpoint_interval": 200,      # æ›´é•¿çš„ä¿å­˜é—´éš”
        "population_size": 4000,         # æ›´å¤§çš„ç§ç¾¤
        "warmup_generations": 200,       # æ›´é•¿çš„é¢„çƒ­æœŸ
        "annealing_strategy": "progressive", # æ¸è¿›å¼ç­–ç•¥
    }
    
    # ğŸ§ª å®éªŒæ€§é…ç½® (ä½¿ç”¨æœ€æ–°å¢å¼ºç‰¹æ€§)
    EXPERIMENTAL_CONFIG = {
        **ENHANCED_TRAINING_CONFIG,
        "mixed_precision": True,         # æ··åˆç²¾åº¦è®­ç»ƒ
        "annealing_strategy": "feature_complexity", # ç‰¹å¾å¤æ‚åº¦é€€ç«
        "annealing_rate": 0.05,          # æ›´æ…¢çš„é€€ç«é€Ÿåº¦
        "population_size": 5000,
        "batch_size": 2500,
        "gpu_memory_fraction": 0.95,
        "pareto_front_size": 200,
        "track_diversity": True,
        "track_convergence": True,
    }
    
    # ğŸ“Š æ•°æ®é€€ç«ä¸“é¡¹æµ‹è¯•é…ç½®
    DATA_ANNEALING_TEST_CONFIG = {
        **ENHANCED_TRAINING_CONFIG,
        "population_size": 1000,
        "generations": 100,
        "enable_multi_objective": False,  # ä¸“æ³¨äºæ•°æ®é€€ç«æ•ˆæœ
        "annealing_strategy": "progressive",
        "min_data_ratio": 0.2,
        "warmup_generations": 20,
        "monitoring_save_interval": 5,
    }
    
    # ğŸ¯ å¤šç›®æ ‡ä¼˜åŒ–ä¸“é¡¹æµ‹è¯•é…ç½®
    MULTI_OBJECTIVE_TEST_CONFIG = {
        **ENHANCED_TRAINING_CONFIG,
        "population_size": 2000,
        "generations": 200,
        "enable_data_annealing": False,   # ä¸“æ³¨äºå¤šç›®æ ‡ä¼˜åŒ–æ•ˆæœ
        "pareto_front_size": 100,
        "enable_hypervolume": True,
        "objective_weights": {
            "sharpe_ratio": 0.2,
            "max_drawdown": 0.2,
            "total_return": 0.2,
            "win_rate": 0.2,
            "volatility": 0.1,
            "profit_factor": 0.1,
        },
    }
    
    # ==============================================================================
    # =================== é€‰æ‹©è¦ä½¿ç”¨çš„é…ç½® (ä¿®æ”¹è¿™é‡Œ) ===========================
    # ==============================================================================
    
    # é€‰æ‹©é…ç½® (å–æ¶ˆæ³¨é‡Šæƒ³è¦ä½¿ç”¨çš„é…ç½®)
    ACTIVE_CONFIG = ENHANCED_TRAINING_CONFIG     # é»˜è®¤å¢å¼ºé…ç½®
    # ACTIVE_CONFIG = QUICK_TEST_CONFIG          # å¿«é€Ÿæµ‹è¯•
    # ACTIVE_CONFIG = HIGH_PERFORMANCE_CONFIG    # é«˜æ€§èƒ½
    # ACTIVE_CONFIG = EXTREME_PERFORMANCE_CONFIG # æé™æ€§èƒ½
    # ACTIVE_CONFIG = CONSERVATIVE_CONFIG        # ä¿å®ˆç­–ç•¥
    # ACTIVE_CONFIG = AGGRESSIVE_CONFIG          # æ¿€è¿›ç­–ç•¥
    # ACTIVE_CONFIG = LONG_TERM_CONFIG           # é•¿æœŸè®­ç»ƒ
    # ACTIVE_CONFIG = EXPERIMENTAL_CONFIG        # å®éªŒæ€§é…ç½®
    # ACTIVE_CONFIG = DATA_ANNEALING_TEST_CONFIG # æ•°æ®é€€ç«æµ‹è¯•
    # ACTIVE_CONFIG = MULTI_OBJECTIVE_TEST_CONFIG # å¤šç›®æ ‡ä¼˜åŒ–æµ‹è¯•
    
    # ==============================================================================
    # ======================= å‚æ•°ä¿®æ”¹åŒºåŸŸç»“æŸ ==================================
    # ==============================================================================

    print("=== å¢å¼ºç‰ˆCUDA GPUåŠ é€Ÿé—ä¼ ç®—æ³•äº¤æ˜“å‘˜è®­ç»ƒå¼€å§‹ ===")
    
    # --- 1. CUDAç¯å¢ƒæ£€æŸ¥ä¸ä¼˜åŒ– ---
    print("\n--- CUDAç¯å¢ƒæ£€æŸ¥ ---")
    cuda_info = check_cuda_compatibility()
    for key, value in cuda_info.items():
        if key == 'gpus':
            print(f"å¯ç”¨GPU:")
            for i, gpu in enumerate(value):
                print(f"  GPU {i}: {gpu['name']} ({gpu['memory_gb']:.1f}GB)")
        elif key not in ['gpus']:
            print(f"{key}: {value}")
    
    if not cuda_info['cuda_available']:
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥CUDAå®‰è£…")
        return
    
    print("âœ… CUDAç¯å¢ƒæ£€æŸ¥é€šè¿‡")
    
    # ä¼˜åŒ–CUDAè®¾ç½®
    optimize_cuda_settings()
    
    # --- 2. è‡ªåŠ¨åŒ–è®¾ç½®ä¸è·¯å¾„ç®¡ç† ---
    output_dir = Path(ACTIVE_CONFIG["results_dir"])
    checkpoint_dir = output_dir / "checkpoints"
    data_dir = Path(ACTIVE_CONFIG["data_directory"])
    
    output_dir.mkdir(exist_ok=True)
    checkpoint_dir.mkdir(exist_ok=True)

    print("\n--- å¢å¼ºç‰ˆè®­ç»ƒå‚æ•° ---")
    for key, value in ACTIVE_CONFIG.items():
        if key == "objective_weights" and isinstance(value, dict):
            print(f"{key}:")
            for obj_name, weight in value.items():
                print(f"  {obj_name}: {weight}")
        else:
            print(f"{key}: {value}")
    print("--------------------\n")
    
    # --- 3. è‡ªåŠ¨å‘ç°æœ€æ–°çš„æ•°æ®æ–‡ä»¶ ---
    try:
        data_files = sorted(data_dir.glob("*.csv"), key=os.path.getmtime, reverse=True)
        if not data_files:
            print(f"æ•°æ®ç›®å½• '{data_dir}' ä¸­æœªæ‰¾åˆ°ä»»ä½•.csvæ–‡ä»¶ã€‚")
            return
        latest_data_file = data_files[0]
        print(f"è‡ªåŠ¨é€‰æ‹©æœ€æ–°çš„æ•°æ®æ–‡ä»¶: {latest_data_file}")
    except FileNotFoundError:
        print(f"æ•°æ®ç›®å½• '{data_dir}' ä¸å­˜åœ¨ã€‚")
        return

    # --- 4. è‡ªåŠ¨å‘ç°æœ€æ–°çš„å¢å¼ºæ£€æŸ¥ç‚¹ ---
    load_checkpoint_path = None
    if ACTIVE_CONFIG["save_checkpoints"]:
        checkpoints = sorted(checkpoint_dir.glob("*enhanced*.pt"), key=os.path.getmtime, reverse=True)
        if not checkpoints:
            # å¦‚æœæ²¡æœ‰å¢å¼ºæ£€æŸ¥ç‚¹ï¼ŒæŸ¥æ‰¾æ™®é€šæ£€æŸ¥ç‚¹
            checkpoints = sorted(checkpoint_dir.glob("*.pt"), key=os.path.getmtime, reverse=True)
        
        if checkpoints:
            latest_checkpoint = checkpoints[0]
            print(f"å‘ç°æœ€æ–°çš„æ£€æŸ¥ç‚¹: {latest_checkpoint}")
            
            # æ£€æŸ¥æ£€æŸ¥ç‚¹ä¸­çš„å‚æ•°æ˜¯å¦ä¸å½“å‰é…ç½®åŒ¹é…
            try:
                ckpt = torch.load(latest_checkpoint, map_location='cpu')
                if ckpt['config'].population_size != ACTIVE_CONFIG['population_size']:
                    print(f"è­¦å‘Š: æ£€æŸ¥ç‚¹ä¸­çš„ç§ç¾¤å¤§å° ({ckpt['config'].population_size}) ä¸å½“å‰é…ç½® ({ACTIVE_CONFIG['population_size']}) ä¸åŒ¹é…ã€‚")
                    print("å°†å¿½ç•¥æ£€æŸ¥ç‚¹ï¼Œå¼€å§‹æ–°çš„è®­ç»ƒã€‚")
                else:
                    load_checkpoint_path = latest_checkpoint
                    print(f"æ£€æŸ¥ç‚¹å‚æ•°åŒ¹é…ï¼Œå°†ä» '{load_checkpoint_path}' ç»§ç»­è®­ç»ƒã€‚")
            except Exception as e:
                print(f"æ— æ³•åŠ è½½æˆ–è§£ææ£€æŸ¥ç‚¹ '{latest_checkpoint}': {e}")
                print("å°†å¿½ç•¥æ£€æŸ¥ç‚¹ï¼Œå¼€å§‹æ–°çš„è®­ç»ƒã€‚")
        else:
            print("æœªå‘ç°æ£€æŸ¥ç‚¹ï¼Œå°†å¼€å§‹æ–°çš„è®­ç»ƒã€‚")

    try:
        # --- 5. å¯åŠ¨æ€§èƒ½ç›‘æ§ ---
        if PERFORMANCE_PROFILER_AVAILABLE:
            start_monitoring(interval=2.0)  # æ¯2ç§’è®°å½•ä¸€æ¬¡å†…å­˜ä½¿ç”¨
            print("ğŸ” æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")
        
        # --- 6. åˆå§‹åŒ–CUDA GPUç®¡ç†å™¨ ---
        with timer("gpu_initialization", "setup"):
            print("åˆå§‹åŒ–CUDA GPUç¯å¢ƒ...")
            gpu_manager = get_cuda_gpu_manager(device_id=ACTIVE_CONFIG.get("gpu_device_id", 0))
        
        # è®¾ç½®GPUå†…å­˜ä½¿ç”¨é™åˆ¶
        if "gpu_memory_fraction" in ACTIVE_CONFIG:
            gpu_manager.set_memory_fraction(ACTIVE_CONFIG["gpu_memory_fraction"])
        
        print(f"âœ… CUDA GPUåŠ é€Ÿå·²{'å¯ç”¨' if gpu_manager.device.type == 'cuda' else 'ç¦ç”¨'}")
        
        # æ˜¾ç¤ºGPUå†…å­˜ä½¿ç”¨æƒ…å†µ
        gpu_alloc, gpu_total, sys_used, sys_total = gpu_manager.get_memory_usage()
        print(f"GPUå†…å­˜: {gpu_alloc:.2f}GB / {gpu_total:.2f}GB")
        print(f"ç³»ç»Ÿå†…å­˜: {sys_used:.2f}GB / {sys_total:.2f}GB")

        # --- 7. æ•°æ®å¤„ç† ---
        with timer("data_processing", "setup"):
            print("\nå¼€å§‹æ•°æ®å¤„ç†...")
            
            processor = GPUDataProcessor(
                window_size=ACTIVE_CONFIG["window_size"],
                normalization_method=ACTIVE_CONFIG["normalization"],
                gpu_manager=gpu_manager
            )
            
            train_features, train_labels = processor.load_and_process_data(latest_data_file)
            print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {train_features.shape}, æ ‡ç­¾æ•°æ®å½¢çŠ¶: {train_labels.shape}")

        # --- 8. é…ç½®å¹¶åˆå§‹åŒ–å¢å¼ºç‰ˆCUDAé—ä¼ ç®—æ³• ---
        with timer("enhanced_ga_initialization", "setup"):
            # è½¬æ¢é€€ç«ç­–ç•¥
            annealing_strategy_map = {
                "temporal": AnnealingStrategy.TEMPORAL,
                "volatility": AnnealingStrategy.VOLATILITY,
                "market_regime": AnnealingStrategy.MARKET_REGIME,
                "feature_complexity": AnnealingStrategy.FEATURE_COMPLEXITY,
                "progressive": AnnealingStrategy.PROGRESSIVE,
            }
            
            enhanced_config = EnhancedGAConfig(
                # åŸºç¡€é—ä¼ ç®—æ³•å‚æ•°
                population_size=ACTIVE_CONFIG["population_size"],
                max_generations=ACTIVE_CONFIG["generations"],
                mutation_rate=ACTIVE_CONFIG["mutation_rate"],
                crossover_rate=ACTIVE_CONFIG["crossover_rate"],
                elite_ratio=ACTIVE_CONFIG["elite_ratio"],
                feature_dim=train_features.shape[1],
                batch_size=ACTIVE_CONFIG["batch_size"],
                early_stop_patience=ACTIVE_CONFIG["early_stop_patience"],
                use_torch_scan=ACTIVE_CONFIG["use_torch_scan"],
                
                # å¢å¼ºåŠŸèƒ½å‚æ•°
                enable_data_annealing=ACTIVE_CONFIG["enable_data_annealing"],
                annealing_strategy=annealing_strategy_map[ACTIVE_CONFIG["annealing_strategy"]],
                annealing_rate=ACTIVE_CONFIG["annealing_rate"],
                min_data_ratio=ACTIVE_CONFIG["min_data_ratio"],
                max_data_ratio=ACTIVE_CONFIG["max_data_ratio"],
                warmup_generations=ACTIVE_CONFIG["warmup_generations"],
                
                enable_multi_objective=ACTIVE_CONFIG["enable_multi_objective"],
                pareto_front_size=ACTIVE_CONFIG["pareto_front_size"],
                enable_hypervolume=ACTIVE_CONFIG["enable_hypervolume"],
                objective_weights=ACTIVE_CONFIG["objective_weights"],
                
                enable_enhanced_monitoring=ACTIVE_CONFIG["enable_enhanced_monitoring"],
                monitoring_save_interval=ACTIVE_CONFIG["monitoring_save_interval"],
                detailed_logging=ACTIVE_CONFIG["detailed_logging"],
                track_diversity=ACTIVE_CONFIG["track_diversity"],
                track_convergence=ACTIVE_CONFIG["track_convergence"],
                export_format=ACTIVE_CONFIG["export_format"],
            )
            
            print(f"å¢å¼ºç‰ˆCUDAé—ä¼ ç®—æ³•é…ç½®: {enhanced_config}")
            ga = EnhancedCudaGA(enhanced_config, gpu_manager)

        # --- 9. æ™ºèƒ½åŠ è½½æˆ–åˆå§‹åŒ–ç§ç¾¤ ---
        if load_checkpoint_path:
            with timer("load_checkpoint", "setup"):
                if "enhanced" in str(load_checkpoint_path):
                    ga.load_checkpoint_enhanced(str(load_checkpoint_path))
                else:
                    ga.load_checkpoint(str(load_checkpoint_path))
        else:
            print("åˆå§‹åŒ–æ–°çš„ç§ç¾¤...")
            ga.initialize_population(seed=int(time.time()))

        # --- 10. å¼€å§‹å¢å¼ºç‰ˆè¿›åŒ– ---
        with timer("enhanced_evolution_process", "training"):
            print("å¼€å§‹å¢å¼ºç‰ˆCUDAåŠ é€Ÿè¿›åŒ–è¿‡ç¨‹...")
            
            # ä½¿ç”¨å›ºå®šçš„æ—¥å¿—æ–‡ä»¶å
            generation_log_file = output_dir / "enhanced_training_history.jsonl"
            print(f"ğŸ“ å¢å¼ºç‰ˆè®­ç»ƒæ—¥å¿—å°†å†™å…¥: {generation_log_file}")
            
            # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå®éªŒæ€§ï¼‰
            if ACTIVE_CONFIG.get("mixed_precision", False):
                print("ğŸ§ª å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰")
            
            results = ga.evolve_enhanced(
                train_features,
                train_labels,
                save_checkpoints=ACTIVE_CONFIG["save_checkpoints"],
                checkpoint_dir=checkpoint_dir,
                
                save_generation_results=ACTIVE_CONFIG["save_generation_results"],
                generation_log_file=generation_log_file,
                generation_log_interval=ACTIVE_CONFIG["generation_log_interval"],
                auto_save_best=ACTIVE_CONFIG["auto_save_best"],
                output_dir=output_dir,
            )

        # --- 11. ä¿å­˜æœ€ç»ˆç»“æœ ---
        print("è®­ç»ƒå®Œæˆï¼Œæ­£åœ¨ä¿å­˜æœ€ç»ˆç»“æœ...")
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜æœ€ä½³ä¸ªä½“
        best_individual_path = output_dir / f"best_individual_enhanced_{timestamp}.npy"
        np.save(best_individual_path, results['best_individual'])
        
        # ä¿å­˜è®­ç»ƒé…ç½®
        config_path = output_dir / f"enhanced_training_config_{timestamp}.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            # è½¬æ¢ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
            serializable_config = ACTIVE_CONFIG.copy()
            
            # å°†Pathå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            for key, value in serializable_config.items():
                if isinstance(value, Path):
                    serializable_config[key] = str(value)
            
            json.dump(serializable_config, f, indent=2, ensure_ascii=False)

        # --- 12. è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š ---
        print("="*80)
        print("              å¢å¼ºç‰ˆCUDA GPUåŠ é€Ÿé—ä¼ ç®—æ³•è®­ç»ƒå®Œæˆ")
        print("="*80)
        print(f"  - ä½¿ç”¨GPU:           {gpu_manager.device}")
        if gpu_manager.device.type == 'cuda':
            print(f"  - GPUåç§°:           {torch.cuda.get_device_name(gpu_manager.device.index)}")
        print(f"  - æœ€ä½³é€‚åº”åº¦:         {results['best_fitness']:.6f}")
        print(f"  - æ€»è®­ç»ƒæ—¶é—´:         {results['total_time']:.2f}ç§’")
        print(f"  - æœ€ç»ˆä»£æ•°:           {results['final_generation']}")
        print(f"  - ç§ç¾¤å¤§å°:           {ACTIVE_CONFIG['population_size']}")
        
        # å¢å¼ºåŠŸèƒ½æŠ¥å‘Š
        if ACTIVE_CONFIG["enable_data_annealing"]:
            annealing_progress = results.get('final_annealing_progress', {})
            print(f"  - æ•°æ®é€€ç«ç­–ç•¥:       {ACTIVE_CONFIG['annealing_strategy']}")
            print(f"  - æœ€ç»ˆæ•°æ®å¤æ‚åº¦:     {annealing_progress.get('complexity_score', 0.0):.3f}")
        
        if ACTIVE_CONFIG["enable_multi_objective"]:
            print(f"  - å¤šç›®æ ‡ä¼˜åŒ–:         å·²å¯ç”¨ ({len(ACTIVE_CONFIG['objective_weights'])}ä¸ªç›®æ ‡)")
            print(f"  - å¸•ç´¯æ‰˜å‰æ²¿å¤§å°:     {ACTIVE_CONFIG['pareto_front_size']}")
        
        if ACTIVE_CONFIG["enable_enhanced_monitoring"]:
            training_summary = results.get('training_summary', {})
            print(f"  - æ”¶æ•›çŠ¶æ€:           {'å·²æ”¶æ•›' if training_summary.get('convergence_achieved', False) else 'æœªæ”¶æ•›'}")
            print(f"  - å¹³å‡ä»£æ•°æ—¶é—´:       {training_summary.get('avg_generation_time', 0.0):.2f}ç§’")
        
        print(f"  - æœ€ä½³ä¸ªä½“:           {best_individual_path}")
        print(f"  - è®­ç»ƒé…ç½®:           {config_path}")
        print(f"  - å®æ—¶æ—¥å¿—:           {generation_log_file}")
        print(f"  - ç»“æœç›®å½•:           {output_dir}")
        
        # å¢å¼ºæŠ¥å‘Šæ–‡ä»¶
        if 'detailed_report_path' in results:
            print(f"  - è¯¦ç»†æŠ¥å‘Š:           {results['detailed_report_path']}")
        if 'progress_plot_path' in results:
            print(f"  - è¿›åº¦å›¾è¡¨:           {results['progress_plot_path']}")
        
        print("="*80)
        
        # æ˜¾ç¤ºæœ€ç»ˆGPUå†…å­˜ä½¿ç”¨æƒ…å†µ
        gpu_alloc, gpu_total, sys_used, sys_total = gpu_manager.get_memory_usage()
        print(f"æœ€ç»ˆGPUå†…å­˜ä½¿ç”¨: {gpu_alloc:.2f}GB / {gpu_total:.2f}GB")
        print(f"æœ€ç»ˆç³»ç»Ÿå†…å­˜ä½¿ç”¨: {sys_used:.2f}GB / {sys_total:.2f}GB")
        
        # --- 13. æ€§èƒ½åˆ†ææŠ¥å‘Š ---
        if PERFORMANCE_PROFILER_AVAILABLE:
            stop_monitoring()
            print("\n" + "="*80)
            print("ğŸ” å¢å¼ºç‰ˆæ€§èƒ½åˆ†ææŠ¥å‘Š")
            print("="*80)
            print_summary(detailed=True)
            
            # ä¿å­˜è¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Š
            performance_report_path = output_dir / f"enhanced_performance_report_{timestamp}.json"
            save_report(performance_report_path)
            print(f"ğŸ“Š è¯¦ç»†æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {performance_report_path}")
            print("="*80)

    except Exception as e:
        print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        # æ¸…ç†GPUç¼“å­˜
        if 'gpu_manager' in locals():
            gpu_manager.clear_cache()
            print("GPUç¼“å­˜å·²æ¸…ç†")


if __name__ == "__main__":
    main()